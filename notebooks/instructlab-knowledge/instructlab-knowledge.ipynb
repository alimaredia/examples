{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af99f876-0ffd-4079-aeb7-4cead05daaf4",
   "metadata": {},
   "source": [
    "# 🐶 Data Pre-Processing: From source PDF to SDG-ready\n",
    "\n",
    "This notebook goes through each of the stages of data pre-processing. Directory-based conventions are used to save intermediate results as a PDF is converted and chunked, QA generation is performed to create a `qna.yaml` file, and finally everything is combined into the inputs for SDG.\n",
    "\n",
    "Once a SDG seed dataset is created, a user can run through an SDG notebook and generate samples.\n",
    "\n",
    "**NOTE**: Starting the notebook using Python 3.11 is recommended. Python 3.12 or later are not yet supported. \n",
    "\n",
    "1. [Data Gathering](#Data-Gathering)\n",
    "1. [Document Conversion](#Document-Conversion)\n",
    "1. [Chunking](#Chunking)\n",
    "1. [Authoring](#Authoring)\n",
    "1. [Create Seed Dataset](#Create-Seed-Dataset-for-SDG)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acd026f-65bd-4393-bb40-f8aa8bd6828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE_NAME = \"default\"\n",
    "\n",
    "WORKSPACE_ROOT = Path(\"workspaces\")\n",
    "WORKSPACE_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "WORKSPACE_DIR = WORKSPACE_ROOT / WORKSPACE_NAME\n",
    "WORKSPACE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SOURCE_DOCUMENT_DIR = WORKSPACE_DIR / \"source_documents\"\n",
    "SOURCE_DOCUMENT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONVERSION_OUTPUT_DIR = WORKSPACE_DIR / \"conversion\"\n",
    "CONVERSION_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHUNKING_OUTPUT_DIR = WORKSPACE_DIR / \"chunking\"\n",
    "CHUNKING_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "AUTHORING_OUTPUT_DIR = WORKSPACE_DIR / \"authoring\"\n",
    "AUTHORING_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SDG_OUTPUT_DIR = WORKSPACE_DIR / \"sdg\"\n",
    "SDG_OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b7ac5-fc2a-40a8-8e1f-e8dd8b1153e7",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "Ensure the necessary PDF files are in `SOURCE_DOCUMENT_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26501e2f-7215-441f-9efa-075f87024893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to convert: [PosixPath('workspaces/default/source_documents/2022-nfl-rulebook-final.pdf'), PosixPath('workspaces/default/source_documents/BofA_InterestChecking_en_ADA.pdf'), PosixPath('workspaces/default/source_documents/2502.01618v3.pdf')]\n"
     ]
    }
   ],
   "source": [
    "files = list(SOURCE_DOCUMENT_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Files to convert: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4904e6-8e12-4473-8301-cba90e61bd8b",
   "metadata": {},
   "source": [
    "## Document Conversion\n",
    "\n",
    "This notebook uses [Docling](https://github.com/docling-project/docling) to convert any type of document into a Docling Document. A Docling Document is the representation of the document after conversion that can be exported as JSON. The JSON output of this notebook can then be used in others such as one that uses Docling's chunking methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91d4b2e-19cd-46e7-a912-ba9b2904c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq docling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fb64b-d089-4844-9330-7f3639819e7a",
   "metadata": {},
   "source": [
    "### Configure Docling conversion pipeline\n",
    "\n",
    "Next we set the configuration options for our conversion pipeline. The PDF Conversion options set here are the defaults. More information about pipeline configuration can be found on Docling.\n",
    "\n",
    "For a complete reference on Docling conversion pipeline configuration, see [PDFPipelineOptions](https://docling-project.github.io/docling/reference/pipeline_options/#docling.datamodel.pipeline_options.PdfPipelineOptions) and [PDFFormatOptions](https://docling-project.github.io/docling/reference/document_converter/#docling.document_converter.InputFormat.XML_JATS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157c5e02-edd1-44f6-b20f-f6b4bda1aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions() # TODO: show the options that can be set\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73400c74-dead-4998-aee2-ddb00ddaa276",
   "metadata": {},
   "source": [
    "Finally, we convert every document into Docling JSON as long as it is a valid file type to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a200039c-b8b2-4087-88ba-7bfb0e393cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaredia/dev/examples/notebooks/instructlab-knowledge/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of JSON output is: /Users/amaredia/dev/examples/notebooks/instructlab-knowledge/workspaces/default/conversion/2022-nfl-rulebook-final.json\n",
      "Path of JSON output is: /Users/amaredia/dev/examples/notebooks/instructlab-knowledge/workspaces/default/conversion/BofA_InterestChecking_en_ADA.json\n",
      "Path of JSON output is: /Users/amaredia/dev/examples/notebooks/instructlab-knowledge/workspaces/default/conversion/2502.01618v3.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_files = []\n",
    "\n",
    "for file in files:\n",
    "    doc = doc_converter.convert(source=file).document\n",
    "    doc_dict = doc.export_to_dict()\n",
    "\n",
    "    json_output_path = CONVERSION_OUTPUT_DIR / f\"{file.stem}.json\"\n",
    "    with open(json_output_path, \"w\") as f:\n",
    "        json.dump(doc_dict, f)\n",
    "        print(f\"Path of JSON output is: {Path(json_output_path).resolve()}\")\n",
    "        json_files.append(json_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafad55e-a4c0-4d6e-9da0-49519fa9bf74",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "The goal of chunking the converted documents is to provide the teacher model small and logical pieces of the source document to generate data off of.\n",
    "\n",
    "In this notebook we are doing chunking with [Docling](https://docling-project.github.io/docling/examples/hybrid_chunking/#hybrid-chunking).\n",
    "\n",
    "The input to this notebook is a docling JSON file created after a docling conversion, or a directory of docling JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482060c-a49f-4345-aa47-d54301939387",
   "metadata": {},
   "source": [
    "### Initialize the Chunker\n",
    "\n",
    "Docling provides two chunkers, the `HierarchicalChunker` and the `HybridChunker`.\n",
    "The `HierarchicalChunker` creates chunks based on the hierarchy in the Docling document\n",
    "\n",
    "The `HybridChunker` builds on the `HierarchicalChunker` and by making it tokenization aware.\n",
    "\n",
    "The `HybridChunker` has options for a `tokenizer`, the `max_tokens` in a chunk, and whether to merge undersized peer chunks. Uncomment the commented out code to configure these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50df9d91-add4-46a1-a69d-0f7f9f69542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "#from transformers import AutoTokenizer\n",
    "\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "#EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#MAX_TOKENS = 1024\n",
    "#\n",
    "# tokenizer = HuggingFaceTokenizer(\n",
    "#     tokenizer=AutoTokenizer.from_pretrained(EMBED_MODEL_ID),\n",
    "#     max_tokens=MAX_TOKENS,  # optional, by default derived from `tokenizer` for HF case\n",
    "#     merge_peers=True # \n",
    "# )\n",
    "\n",
    "chunker = HybridChunker(\n",
    "    #tokenizer=tokenizer,\n",
    "    #merge_peers=True,  # whether to merge undersized chunks - defaults to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce1d6f-b8d3-470c-b3c9-675911f0ee92",
   "metadata": {},
   "source": [
    "### Load and chunk the converted docling document\n",
    "\n",
    "Next lets convert the document we want to chunk up into a Docling Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db983c05-4aa6-4261-9283-2adab69bfbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1798 chunks from 2022-nfl-rulebook-final\n",
      "Extracted 10 chunks from BofA_InterestChecking_en_ADA\n",
      "Extracted 52 chunks from 2502.01618v3\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "docs = []\n",
    "for file in json_files:\n",
    "    # reconvert the docling JSON for chunking\n",
    "    doc = DocumentConverter().convert(source=file)\n",
    "    \n",
    "    chunk_iter = chunker.chunk(dl_doc=doc.document)\n",
    "    chunk_objs = list(chunk_iter)\n",
    "    chunks = [chunker.contextualize(chunk=chunk) for chunk in chunk_objs]\n",
    "\n",
    "    print(f\"Extracted {len(chunks)} chunks from {doc.document.name}\")\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        c = dict(chunk=chunk, file=doc.document.name)\n",
    "        all_chunks.append(c)\n",
    "    \n",
    "    docs.append(dict(chunk_objs=chunk_objs,file=doc.document.name))\n",
    "\n",
    "\n",
    "# TODO: support multiple files save all chunks to single file for review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb38545-eb84-4923-8fc4-d10ed08eab26",
   "metadata": {},
   "source": [
    "### View the Chunks\n",
    "\n",
    "To view the chunks, run through the following cell. As you can see the document is broken into small pieces with metadata about the chunk based on the document's format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fdf34c7-9829-43d2-bf9f-7d1d55bb6a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 OFFICIAL PLAYING RULES OF THE NATIONAL FOOTBALL LEAGUE\n",
      "Roger Goodell, Commissioner\n"
     ]
    }
   ],
   "source": [
    "print(all_chunks[0][\"chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4160f-7508-4c72-b28d-b56aa4975b26",
   "metadata": {},
   "source": [
    "### Save all chunks to a JSON file\n",
    "\n",
    "All chunks are saved to a JSON file called chunks.jsonl in CHUNKING_OUTPUT_DIR. This file is one of the inputs father below when we create the seed dataset for SDG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e70d576-a2bc-4274-b660-1cbe051968b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_file_path = CHUNKING_OUTPUT_DIR / \"chunks.jsonl\"\n",
    "with open(chunks_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for chunk in all_chunks:\n",
    "        json.dump(chunk, file)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510f8c7-8cd3-4867-8742-9f4f9cda9e9f",
   "metadata": {},
   "source": [
    "## Authoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c48e52-cda7-48ac-84dc-0b844aed5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq docling-sdg\n",
    "\n",
    "# TODO: replace with above after https://github.com/docling-project/docling-sdg/pull/31 merges\n",
    "#!pip install -qq git+https://github.com/anastasds/docling-sdg@d15de2c5a81bfe166f66f412fc4b23728065f396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a165c38-843b-4c89-a8ad-6195b998e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking and filtering document 2022-nfl-rulebook-final\n",
      "Created dataset 2022-nfl-rulebook-final with 720 QA chunks\n",
      "Chunking and filtering document BofA_InterestChecking_en_ADA\n",
      "Created dataset BofA_InterestChecking_en_ADA with 8 QA chunks\n",
      "Chunking and filtering document 2502.01618v3\n",
      "Created dataset 2502.01618v3 with 45 QA chunks\n"
     ]
    }
   ],
   "source": [
    "from docling_sdg.qa.utils import get_qa_chunks\n",
    "\n",
    "filters = [\n",
    "    lambda chunk: len(str(chunk.text)) > 500\n",
    "]\n",
    "\n",
    "dataset = {}\n",
    "for doc in docs:\n",
    "    print(f\"Chunking and filtering document {doc[\"file\"]}\")\n",
    "    \n",
    "    # get_qa_chunks expects a list[DocChunk] which we already have from doc[\"chunk_objs\"] in the chunking section\n",
    "    qa_chunks = list(get_qa_chunks(doc[\"file\"], doc[\"chunk_objs\"], filters)) #TODO: decouple reference to chunk_objs from above)\n",
    "    dataset[doc[\"file\"]] = qa_chunks\n",
    "    \n",
    "    print(f\"Created dataset {doc[\"file\"]} with {len(qa_chunks)} QA chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ec755-e3de-40ab-bf3a-23ebb29a705d",
   "metadata": {},
   "source": [
    "### Initialize QA generator, supplying details for which model to use\n",
    "\n",
    "GenerateOptions controls which model is used for QA generation by setting generate_options.provider below. Three options are available:\n",
    "\n",
    "* LlmProviders.WATSONX for watsonx\n",
    "* LlmProviders.OPENAI for OpenAI\n",
    "* LlmProviders.OPENAI_LIKE for any model provider with OpenAI compatible APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "874d4de8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "API_KEY = \"none\"  # the API access key for your account ( cannot be empty )\n",
    "API_URL = \"http://127.0.0.1:11434/v1\"  # the URL of your model's API\n",
    "MODEL_ID = \"granite3.3\" # the name of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b702267e-f550-4bc2-bce4-c0fcecbbd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_sdg.qa.generate import Generator\n",
    "from docling_sdg.qa.base import GenerateOptions, LlmProvider\n",
    "from pydantic import SecretStr\n",
    "\n",
    "generate_options = GenerateOptions(project_id=\"project_id\")\n",
    "generate_options.provider = LlmProvider.OPENAI_LIKE\n",
    "generate_options.api_key = SecretStr(API_KEY)\n",
    "generate_options.url = API_URL\n",
    "generate_options.model_id = MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919199c0-3747-409a-85ab-0155ef3ebe9d",
   "metadata": {},
   "source": [
    "### Configure subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1197d4e-8354-45e3-9ec9-85c78ba36548",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHUNKS_PER_FILE_TO_SELECT_FOR_AUTHORING = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2421d07-3e6c-4355-95f4-da8e157557c7",
   "metadata": {},
   "source": [
    "### Run QA generation on selected chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e57edff5-9a13-47fb-9248-9140ae5baaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chunks that looks like:\n",
      "This edition of the Official Playing Rules of the  National Football League  contains all current rules governing the playing of professional football that are in effect for the 2022 NFL season. Member clubs of the League may amend the rules from time to time, pursuant to the applicable voting procedures of the NFL Constitution and Bylaws.\n",
      "Any intra-League dispute or call for interpretation in connection with these rules will be decided by the Commissioner of the League, whose ruling will be final.\n",
      "Because inter-conference games are played throughout the preseason, regular season, and postseason in  the  NFL, all  rules contained in  this  book apply uniformly to both the American and National Football Conferences.\n",
      "Where the word 'illegal' appears in this rule book, it is an institutional term of art pertaining strictly to actions that violate NFL playing rules. It is not meant to connote illegality under any public law or the rules or regulations of any other organization.\n",
      "The word 'flagrant,' when used here to describe an action by a player, is meant to indicate that the degree of a violation of the rules-usually a personal foul or  unnecessary roughness-is extremely objectionable, conspicuous, unnecessary, avoidable, or gratuitous. 'Flagrant' in these rules does not necessarily imply malice on the part of the fouling player or an intention to injure an opponent.\n",
      "Copyright © 2022 by the National Football League. All rights reserved. Printed in the United States of America.\n",
      "Bottom of the yard line numbers must be 12 yards from the sideline.\n",
      "Selected 2 contexts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-nfl-rulebook-final: Status.SUCCESS\n",
      "processing chunks that looks like:\n",
      "Opening Deposit\n",
      "$100 or more\n",
      "Interest Rate\n",
      "This account earns interest at a variable rate. You can find current rate information at bankofamerica.com, by calling the number on your account statement or visiting a financial center.\n",
      "Monthly\n",
      "Maintenance\n",
      "Fee\n",
      "$25.00 each month. You can avoid the Monthly Maintenance Fee when you meet ONE of the following requirements during each statement cycle:\n",
      "• Maintain a minimum daily balance of $20,000 or more in your account OR\n",
      "• Be a member of the Preferred Rewards program. Learn more at bankofamerica.com/preferred-rewards.\n",
      "ATM fees\n",
      "Bank of America ATMs\n",
      "No ATM fee\n",
      "For deposits, withdrawals, transfers or balance inquiries\n",
      "Non-Bank of America ATMs\n",
      "$2.50\n",
      "In the U.S., plus any fee charged by the ATM's operator\n",
      "$5.00\n",
      "Outside the U.S., plus any fee charged by the ATM's operator\n",
      "Selected 2 contexts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BofA_InterestChecking_en_ADA: Status.SUCCESS\n",
      "processing chunks that looks like:\n",
      "Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT4o accuracy in only 4 rollouts, while Qwen2.5Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code, videos, and further information available at probabilistic-inference-scaling.github.io/ .\n",
      "Selected 2 contexts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502.01618v3: Status.SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random #TODO: replace random sampling with subset selection\n",
    "\n",
    "generated_files = []\n",
    "\n",
    "for doc, chunks in dataset.items():\n",
    "    generate_options.generated_file = AUTHORING_OUTPUT_DIR / f\"qagen-{doc}.json\"\n",
    "    gen = Generator(generate_options=generate_options)\n",
    "    print(f\"processing chunks that looks like:\\n{chunks[0].text}\")\n",
    "    selected_chunks = random.sample(chunks, NUM_CHUNKS_PER_FILE_TO_SELECT_FOR_AUTHORING)\n",
    "    print(f\"Selected {len(selected_chunks)} contexts\")\n",
    "\n",
    "    Path.unlink(generate_options.generated_file, missing_ok=True)\n",
    "    results = gen.generate_from_chunks(selected_chunks) # automatically saves to file\n",
    "    generated_files.append(generate_options.generated_file)\n",
    "\n",
    "    print(f\"{doc}: {results.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64b8f0-dd6c-4776-8646-9731433f909b",
   "metadata": {},
   "source": [
    "### Read generated QAs and restructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9df2c533-30d7-4c30-9907-7c5655fd2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated QA pairs for 13 contexts\n",
      "[{'question': 'What is the mandatory color for the lower portion of game socks and/or leg coverings?', 'answer': 'White'}, {'question': \"What are the color options for a player's uniform, including helmets, jerseys, pants, and game socks and/or leg coverings?\", 'answer': 'Players are permitted to wear only the colors or a combination of those colors established for their NFL club in the League Constitution and Bylaws, with white also being an available color for jerseys and mandatory for the lower portion of game socks and/or leg coverings. Each player on a given team must wear the same colors on his uniform as all other players on his team in the same game.'}, {'question': 'Based on the policy, why is it important for players to present an appearance that is appropriate to representing their individual clubs and the National Football League?', 'answer': 'The policy emphasizes professionalism and representation, suggesting that the appearance of players reflects on both their individual clubs and the league as a whole. Therefore, maintaining an appropriate appearance is important for upholding the image and reputation of both the club and the league.'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "from textwrap import wrap\n",
    "\n",
    "qnas = {}\n",
    "chunk_id_to_text = {}\n",
    "for file in generated_files:\n",
    "    with open(file, \"rt\") as f:\n",
    "        for line in f.readlines():\n",
    "            entry = json.loads(line)\n",
    "            chunk_id = entry['chunk_id']\n",
    "            if chunk_id not in chunk_id_to_text:\n",
    "                chunk_id_to_text[chunk_id] = entry['context']\n",
    "            if chunk_id not in qnas:\n",
    "                qnas[chunk_id] = []\n",
    "            qnas[chunk_id].append({'question': entry['question'], 'answer': entry['answer']})\n",
    "\n",
    "print(f\"Generated QA pairs for {len(qnas)} contexts\")\n",
    "print(list(qnas.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d6c26-f4d5-420d-ae78-ac28cf39efd3",
   "metadata": {},
   "source": [
    "### Define metadata for qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7130e90-2b65-4008-86f7-194da74a9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_OUTLINE = \"A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods\"\n",
    "DOMAIN = \"artificial intelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa8927-e56c-448b-b88b-f8d854c25d4d",
   "metadata": {},
   "source": [
    "### Output qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7f26460-737f-4940-b58a-ef6caea313d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qna.yaml saved to: workspaces/default/authoring/qna.yaml\n"
     ]
    }
   ],
   "source": [
    "qna_output_path = AUTHORING_OUTPUT_DIR / \"qna.yaml\"\n",
    "\n",
    "# The following creates a data structure for outputting in the expected format for qna.yaml\n",
    "# TODO: extract into utils library\n",
    "\n",
    "def str_presenter(dumper, data):\n",
    "  if len(data.splitlines()) > 1:  # check for multiline string\n",
    "    return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n",
    "  elif len(data) > 80:\n",
    "    data = \"\\n\".join(wrap(data, 80))\n",
    "    return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n",
    "  return dumper.represent_scalar('tag:yaml.org,2002:str', data)\n",
    "\n",
    "yaml.add_representer(str, str_presenter)\n",
    "\n",
    "# to use with safe_dump:\n",
    "yaml.representer.SafeRepresenter.add_representer(str, str_presenter)\n",
    "\n",
    "class IndentedDumper(yaml.Dumper):\n",
    "    def increase_indent(self, flow=False, indentless=False):\n",
    "        return super(IndentedDumper, self).increase_indent(flow, False)\n",
    "\n",
    "data = {'seed_examples': []}\n",
    "for chunk_id, context in chunk_id_to_text.items():\n",
    "    data['seed_examples'].append({\n",
    "        'context': context,\n",
    "        'questions_and_answers': [\n",
    "            {\n",
    "                'question': example['question'],\n",
    "                'answer': example['answer'],\n",
    "            } for example in qnas[chunk_id]\n",
    "        ]\n",
    "    })\n",
    "\n",
    "data['document_outline'] = DOCUMENT_OUTLINE\n",
    "data['domain'] = DOMAIN\n",
    "\n",
    "Path.unlink(qna_output_path, missing_ok=True) # shouldn't be necessary but was. jupyter caching thing?\n",
    "with open(qna_output_path, 'w') as yaml_file:\n",
    "    yaml.dump(data, yaml_file, Dumper=IndentedDumper, default_flow_style=False, sort_keys=False, width=80)\n",
    "\n",
    "print(f\"qna.yaml saved to: {qna_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ea149-844b-4330-90ec-d0ca7ab12b90",
   "metadata": {},
   "source": [
    "### View generated qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1293d445-b826-4b92-ad20-9b121ac60e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_examples:\n",
      "  - context: |-\n",
      "      ARTICLE 1.  GENERAL POLICY. Throughout the game-day period while in view of the stadium and television audience, including during team pregame warm-ups, all players must dress in a professional manner under the uniform standards. The helmet and mandatory padding referenced in Article 3 below are intended to provide reasonable protection to a player while reasonably avoiding risk of injury to other players. The development of Playing Rules should be governed by this Article. Players generally must present an appearance that is appropriate to representing their individual clubs and the National Football League. The term uniform, as used in this policy, applies to every piece of equipment worn by a player, including helmet, shoulder pads, thigh pads, knee pads, and any other item of protective gear, and to every visible item of apparel, including but not limited to pants, jerseys, wristbands, gloves, game socks and/or leg coverings, shoes, visible undergarments, and accessories such as headwear worn under helmets and hand towels. All visible items worn on game day by players must be issued by the club or the League, or, if from outside sources, must have approval in advance by the League office.\n",
      "      ARTICLE 2.  TEAM COLORS. Pursuant to the official colors established for each NFL club in the League Constitution and Bylaws, playing squads are permitted to wear only those colors or a combination of those colors for helmets, jerseys, pants, and game socks and/or leg coverings; provided that white is also an available color for jerseys and mandatory color for the lower portion of game socks and/or leg coverings. (See 5-4-3-Item 6, 'Game socks and/or leg coverings,' below). Each player on a given team must wear the same colors on his uniform as all other players on his team in the same game. Home clubs shall choose their jersey color (either white or official team color), and visiting clubs must wear the opposite. For preseason, regular season, or postseason\n",
      "    questions_and_answers:\n",
      "      - question: |-\n",
      "          What is the mandatory color for the lower portion of game socks and/or leg\n",
      "          coverings?\n",
      "        answer: White\n",
      "      - question: |-\n",
      "          What are the color options for a player's uniform, including helmets, jerseys,\n",
      "          pants, and game socks and/or leg coverings?\n",
      "        answer: |-\n",
      "          Players are permitted to wear only the colors or a combination of those colors\n",
      "          established for their NFL club in the League Constitution and Bylaws, with white\n",
      "          also being an available color for jerseys and mandatory for the lower portion of\n",
      "          game socks and/or leg coverings. Each player on a given team must wear the same\n",
      "          colors on his uniform as all other players on his team in the same game.\n",
      "      - question: |-\n",
      "          Based on the policy, why is it important for players to present an appearance\n",
      "          that is appropriate to representing their individual clubs and the National\n",
      "          Football League?\n",
      "        answer: |-\n",
      "          The policy emphasizes professionalism and representation, suggesting that the\n",
      "          appearance of players reflects on both their individual clubs and the league as\n",
      "          a whole. Therefore, maintaining an appropriate appearance is important for\n",
      "          upholding the image and reputation of both the club and the league.\n",
      "  - context: |-\n",
      "      Third-and-5 on B40. End A2 is illegally chucked out of bounds at the B30, immediately returns inbounds, and is interfered with by B2 at the B25, while the pass is in the air. B2 intercepts the ball and is tackled at the B40.\n",
      "      Ruling: A's ball, first-and-10 on B25. Since A2 was illegally contacted out of bounds, he is an eligible receiver as soon as he re-establishes, and this is defensive pass interference. Decline the illegal contact penalty. A2 must make an immediate attempt to return inbounds in order to be eligible.\n",
      "    questions_and_answers:\n",
      "      - question: What is the ruling of the play?\n",
      "        answer: A's ball, first-and-10 on B25.\n",
      "      - question: What are the key penalties and their outcomes in this play?\n",
      "        answer: |-\n",
      "          There are two penalties in this play: illegal contact and defensive pass\n",
      "          interference. The illegal contact penalty is declined, and the defensive pass\n",
      "          interference results in A's ball, first-and-10 on B25.\n",
      "  - context: |-\n",
      "      Fourth-and-3 on B20. On a field-goal attempt, center A5 lines up on the end of\n",
      "      the line in the middle of the field. Holder A2 and kicker A1 line up directly\n",
      "      behind A5. The rest of the team is lined up at the inbounds line 15 yards away\n",
      "      from center A5. The ball is snapped by A5 to up-back A4, who is lined up behind\n",
      "      the rest of the line at the inbounds spot. A5 did not snap the ball through his\n",
      "      legs. A4 runs to the B5 where he is tackled. Center A5: (a) reported as eligible\n",
      "      prior to the snap; or (b) A5 did not report as eligible prior to the snap.\n",
      "    questions_and_answers:\n",
      "      - question: Did center A5 report as eligible prior to the snap?\n",
      "        answer: No, according to the passage, A5 did not report as eligible prior\n",
      "          to the snap.\n",
      "      - question: What is the formation of the team at the time of the snap?\n",
      "        answer: |-\n",
      "          At the time of the snap, center A5 is at the end of the line in the middle of\n",
      "          the field, holder A2 and kicker A1 are directly behind A5, and the rest of the\n",
      "          team is lined up at the inbounds line 15 yards away from center A5. The ball is\n",
      "          snapped by A5 to up-back A4, who is lined up behind the rest of the line at the\n",
      "          inbounds spot.\n",
      "      - question: Based on the information provided, can we determine if this was\n",
      "          a legal play?\n",
      "        answer: |-\n",
      "          No, the passage does not provide enough information to determine if this was a\n",
      "          legal play. It only mentions that center A5 did not report as eligible prior to\n",
      "          the snap, but it does not specify if this is a requirement for the play or if\n",
      "          any rules were violated.\n",
      "  - context: |-\n",
      "      (a) B's ball, first-and-10 on B27. The kick ended behind the line of scrimmage, so there is no 'spot of kick' option.\n",
      "      (b) B's ball, first-and-10 on B17. The kick ended behind the line of scrimmage, so there is no 'spot of kick' option. Since A2 legally advanced the untouched kick recovered behind the line, his advance is legal, and Team B takes over on downs at the dead ball spot.\n",
      "      (c) A's ball, first-and-10 on B14. The kick ended behind the line of scrimmage, so there is no 'spot of kick' option. Since A2 legally advanced the untouched kick recovered behind the line, his advance is legal. A2 reached the line to gain, so it is a first down for Team A.\n",
      "      (d) B's ball, first-and-10 on B30. Illegal forward pass, as the ball has been beyond the line. The penalty is five yards from the previous spot and a loss of down. The kick ended behind the line of scrimmage, so there is no 'spot of kick' option.\n",
      "      (e) B's ball, first-and-10 on B31. The kick ended behind the line of scrimmage, so there is no 'spot of kick' option. Team B keeps the ball at the dead ball spot.\n",
      "      Note : Team B does not have the option to take the ball at the spot of the kick if: (1) B touches the ball beyond the line of scrimmage; (2) the kick ends behind the line; or (3) a Team B foul during the play is accepted.\n",
      "    questions_and_answers:\n",
      "      - question: |-\n",
      "          What happens if a team recovers an untouched kick behind the line of scrimmage\n",
      "          and legally advances it?\n",
      "        answer: |-\n",
      "          The team that advanced the kick legally takes over on downs at the dead ball\n",
      "          spot.\n",
      "      - question: |-\n",
      "          What are the conditions under which Team B cannot take the ball at the spot of\n",
      "          the kick?\n",
      "        answer: |-\n",
      "          Team B cannot take the ball at the spot of the kick if B touches the ball beyond\n",
      "          the line of scrimmage, the kick ends behind the line, or a Team B foul during\n",
      "          the play is accepted.\n",
      "      - question: |-\n",
      "          If Team B commits an illegal forward pass beyond the line of scrimmage, what is\n",
      "          the penalty?\n",
      "        answer: The penalty is five yards from the previous spot and a loss of down.\n",
      "  - context: |-\n",
      "      Second-and-10 on A20. A2 takes a handoff and runs to the 50. As he is being\n",
      "      tackled, he hands the ball to A3 who is running parallel with him. A3 initially\n",
      "      touches the ball at the 50, but doesn't control it until the B48 ahead of A2. A3\n",
      "      runs for a touchdown. Ruling: Reviewable. Legal handoff, touchdown. For it to be\n",
      "      illegal, the player receiving the handoff must be clearly in advance of the\n",
      "      player making the handoff when he first touches the ball. Only the Replay\n",
      "      Official can initiate a review of this play.\n",
      "    questions_and_answers:\n",
      "      - question: Who can initiate a review of the play?\n",
      "        answer: Only the Replay Official can initiate a review of this play.\n",
      "      - question: What was the outcome of the play and what was the ruling on its\n",
      "          legality?\n",
      "        answer: |-\n",
      "          A3 ran for a touchdown and the ruling was that it was a legal handoff and\n",
      "          touchdown.\n",
      "      - question: |-\n",
      "          Based on the information provided, was A3 in advance of A2 when he first touched\n",
      "          the ball?\n",
      "        answer: |-\n",
      "          No, A3 initially touched the ball at the 50, but didn't control it until the B48\n",
      "          ahead of A2.\n",
      "  - context: \"\\xB7 Cash, direct deposits, wire transfers: On the day we receive them.\\n\\\n",
      "      \\xB7 Checks: Usually the next business day, if deposited before the financial\\\n",
      "      \\ center or ATM cutoff time.\\n\\xB7 Mobile Check Deposit: Usually the next business\\\n",
      "      \\ day if deposited by applicable cutoff times. Please refer to Deposit Checks\\\n",
      "      \\ , then Help in the Mobile Banking app for additional details and terms and\\\n",
      "      \\ conditions.\\n\\xB7 If we place a hold on your deposit, we'll let you know the\\\n",
      "      \\ hold reason and when your funds will be available. This is typically provided\\\n",
      "      \\ at the time of deposit but may also be mailed later. Deposits greater than\\\n",
      "      \\ $5,525 and checks deposited within the first 30 days of account opening may\\\n",
      "      \\ be held longer.\"\n",
      "    questions_and_answers:\n",
      "      - question: What is the usual availability of cash and wire transfers when received?\n",
      "        answer: On the day they are received.\n",
      "      - question: What is the usual availability of funds for different types of deposits?\n",
      "        answer: |-\n",
      "          Direct deposits and wire transfers are usually available on the day they are\n",
      "          received, checks are usually available the next business day if deposited before\n",
      "          the cutoff time, and mobile check deposits are usually available the next\n",
      "          business day if deposited by applicable cutoff times.\n",
      "      - question: If a deposit is held, when are the funds typically available?\n",
      "        answer: |-\n",
      "          If a deposit is held, the funds will typically be available when the hold is\n",
      "          released, which is typically communicated at the time of deposit but may also be\n",
      "          mailed later. Deposits greater than $5,525 and checks deposited within the first\n",
      "          30 days of account opening may be held longer.\n",
      "  - context: \"Opening Deposit\\n$100 or more\\nInterest Rate\\nThis account earns interest\\\n",
      "      \\ at a variable rate. You can find current rate information at bankofamerica.com,\\\n",
      "      \\ by calling the number on your account statement or visiting a financial center.\\n\\\n",
      "      Monthly\\nMaintenance\\nFee\\n$25.00 each month. You can avoid the Monthly Maintenance\\\n",
      "      \\ Fee when you meet ONE of the following requirements during each statement\\\n",
      "      \\ cycle:\\n\\u2022 Maintain a minimum daily balance of $20,000 or more in your\\\n",
      "      \\ account OR\\n\\u2022 Be a member of the Preferred Rewards program. Learn more\\\n",
      "      \\ at bankofamerica.com/preferred-rewards.\\nATM fees\\nBank of America ATMs\\n\\\n",
      "      No ATM fee\\nFor deposits, withdrawals, transfers or balance inquiries\\nNon-Bank\\\n",
      "      \\ of America ATMs\\n$2.50\\nIn the U.S., plus any fee charged by the ATM's operator\\n\\\n",
      "      $5.00\\nOutside the U.S., plus any fee charged by the ATM's operator\"\n",
      "    questions_and_answers:\n",
      "      - question: What is the variable interest rate for this account?\n",
      "        answer: |-\n",
      "          The text does not provide the variable interest rate for this account. It can be\n",
      "          found at bankofamerica.com, by calling the number on your account statement or\n",
      "          visiting a financial center.\n",
      "      - question: What are the ways to avoid the monthly maintenance fee of $25?\n",
      "        answer: |-\n",
      "          The monthly maintenance fee of $25 can be avoided by maintaining a minimum daily\n",
      "          balance of $20,000 or more in the account or by being a member of the Preferred\n",
      "          Rewards program.\n",
      "      - question: |-\n",
      "          If I have a balance of $20,000 in my account, will I still be charged the ATM\n",
      "          fee for using a non-Bank of America ATM?\n",
      "        answer: |-\n",
      "          No, if you maintain a minimum daily balance of $20,000 or more in your account,\n",
      "          you will not be charged the ATM fee for using a non-Bank of America ATM.\n",
      "          However, you may still be charged a fee by the ATM's operator.\n",
      "  - context: \"\\xB7 To help you avoid fees, we won't authorize ATM withdrawals or everyday\\\n",
      "      \\ debit card purchases when you don't have enough money in your account at the\\\n",
      "      \\ time of the transaction.\\n\\xB7 When we determine you don't have enough money\\\n",
      "      \\ in your account to cover other items such as checks or scheduled payments,\\\n",
      "      \\ we'll either authorize and pay the item and overdraw your account (an overdraft\\\n",
      "      \\ item),  or decline or return the item unpaid (a returned item). When 1 this\\\n",
      "      \\ happens, you may be charged a fee. See details below.\\n\\u2022 We offer two\\\n",
      "      \\ overdraft setting options for how you want us to process your other transactions.\"\n",
      "    questions_and_answers:\n",
      "      - question: |-\n",
      "          What happens when there is not enough money in the account to cover other items\n",
      "          like checks or scheduled payments?\n",
      "        answer: |-\n",
      "          The bank will either authorize and pay the item and overdraw the account, or\n",
      "          decline or return the item unpaid.\n",
      "      - question: |-\n",
      "          What are the two overdraft setting options the bank offers for processing other\n",
      "          transactions?\n",
      "        answer: The bank offers two overdraft setting options for processing other\n",
      "          transactions.\n",
      "      - question: |-\n",
      "          If the bank overdraws an account and charges a fee, why might a customer\n",
      "          consider changing their overdraft setting option?\n",
      "        answer: |-\n",
      "          A customer might consider changing their overdraft setting option to avoid or\n",
      "          reduce the frequency of overdraft fees.\n",
      "  - context: \"Review all the features and benefits of your new account at bankofamerica.com/quickstart\\n\\\n",
      "      For questions, schedule an appointment to visit a financial center at bankofamerica.com/appointments\\n\\\n",
      "      Call us at 800.432.1000\\nAdditional fee waivers may be available to Bank of\\\n",
      "      \\ America Private Bank and qualified Merrill Lynch Wealth Management \\xAE clients.\\\n",
      "      \\ Please contact your advisor to learn more. Merrill Lynch, Pierce, Fenner &\\\n",
      "      \\ Smith Incorporated (also referred to as 'MLPF&S' or 'Merrill') makes available\\\n",
      "      \\ certain investment products sponsored, managed, distributed or provided by\\\n",
      "      \\ companies that are affiliates of Bank of America Corporation ('BofA Corp.').\\\n",
      "      \\ MLPF&S is a registered broker-dealer, registered investment advisor, Member\\\n",
      "      \\ SIPC and a wholly owned subsidiary of BofA Corp.\\nInvestment products:\\nAre\\\n",
      "      \\ Not FDIC Insured\\nAre Not Bank Guaranteed\\nMay Lose Value\\nBanking products\\\n",
      "      \\ are provided by Bank of America, N.A. and affiliated banks, Members FDIC and\\\n",
      "      \\ wholly owned subsidiaries of Bank of America Corporation.\"\n",
      "    questions_and_answers:\n",
      "      - question: What is the phone number to contact Bank of America?\n",
      "        answer: 800.432.1000\n",
      "      - question: What services does Bank of America offer through its website?\n",
      "        answer: |-\n",
      "          Bank of America offers account review, fee waiver inquiries, appointment\n",
      "          scheduling, and customer service through its website.\n",
      "      - question: |-\n",
      "          If a Bank of America Private Bank or Merrill Lynch Wealth Management client\n",
      "          contacts their advisor regarding additional fee waivers, what would be the\n",
      "          outcome?\n",
      "        answer: The client would learn more about any available fee waivers.\n",
      "  - context: |-\n",
      "      Additional fees, 1 = Additional fees. Additional fees, 2 = Additional fees.\n",
      "      Statement copies, 1 = No fee. Statement copies, 2 = Paper copies available upon\n",
      "      request. Printable statements are available in Online Banking.. Check images, 1\n",
      "      = No fee. Check images, 2 = Printable check images from the last 18 months are\n",
      "      available online.. Ordering checks, 1 = Varies. Ordering checks, 2 = No fee on\n",
      "      standard styles and discounts on certain styles. Card replacement, 1 = No fee.\n",
      "      Card replacement, 2 = For each ATM or debit card. Card replacement, 1 = $15.00.\n",
      "      Card replacement, 2 = For rush delivery. Stop payment, 1 = WAIVED $30.00. Stop\n",
      "      payment, 2 = For each request. Cashier's checks, 1 = $15.00. Cashier's checks, 2\n",
      "      = For each check. Domestic wire transfers, 1 = WAIVED $15.00. Domestic wire\n",
      "      transfers, 2 = For each incoming wire transfer. Domestic wire transfers, 1 =\n",
      "      $30.00. Domestic wire transfers, 2 = For each outgoing wire transfer.\n",
      "      International wire transfers, 1 = $15.00. International wire transfers, 2 = For\n",
      "      each incoming wire transfer: If received in a foreign currency, it will be\n",
      "      converted into U.S. Dollars using the applicable exchange rate determined solely\n",
      "      by us.. International wire transfers, 1 = No wire fee. International wire\n",
      "      transfers, 2 = For each outgoing wire transfer sent in foreign currency. Please\n",
      "      be advised, exchange rate markups will apply. See below.. International wire\n",
      "      transfers, 1 = $45.00. International wire transfers, 2 = For each outgoing wire\n",
      "      transfer sent in U.S. Dollars. For international wire transfers, other fees may\n",
      "      also apply, including those charged by recipient's financial institution,\n",
      "      foreign taxes, and other fees that are part of the wire transfer process. We\n",
      "      profit from markups associated with the currency conversion included in our\n",
      "      exchange rate (determined solely by us). Before sending in foreign currency, you\n",
      "      should consider factors that impact the total cost or the amount available after\n",
      "      transfer., 1 = For international wire transfers, other fees may also apply,\n",
      "      including those charged by recipient's financial institution, foreign taxes, and\n",
      "      other fees that are part of the wire transfer process. We profit from markups\n",
      "      associated with the currency conversion included in our exchange rate\n",
      "      (determined solely by us). Before sending in foreign currency, you should\n",
      "      consider factors that impact the total cost or\n",
      "    questions_and_answers:\n",
      "      - question: What is the fee for ordering checks with standard styles?\n",
      "        answer: No fee\n",
      "      - question: What are the fees associated with international wire transfers?\n",
      "        answer: |-\n",
      "          For incoming wire transfers in foreign currency, there is a $15 fee and a\n",
      "          currency conversion markup. For incoming wire transfers in US dollars, there is\n",
      "          a $45 fee. For outgoing wire transfers in foreign currency, there is a $15 fee\n",
      "          and a currency conversion markup. For outgoing wire transfers in US dollars,\n",
      "          there is a $30 fee. Other fees may also apply, including those charged by the\n",
      "          recipient's financial institution, foreign taxes, and other fees that are part\n",
      "          of the wire transfer process.\n",
      "      - question: |-\n",
      "          Considering the information about international wire transfers, why might it be\n",
      "          more cost-effective to send a wire transfer in a foreign currency rather than in\n",
      "          US dollars?\n",
      "        answer: |-\n",
      "          Sending a wire transfer in a foreign currency might be more cost-effective\n",
      "          because, even though there is a currency conversion markup, the fee for incoming\n",
      "          wire transfers in foreign currency is lower than the fee for incoming wire\n",
      "          transfers in US dollars. However, other factors such as fees charged by the\n",
      "          recipient's financial institution, foreign taxes, and other fees that are part\n",
      "          of the wire transfer process should also be considered.\n",
      "  - context: |-\n",
      "      Closed-Source LLMs, Method = . Closed-Source LLMs, MATH500 = . Closed-Source\n",
      "      LLMs, AIME 2024 = . GPT-4o, Method = -. GPT-4o, MATH500 = 76.2. GPT-4o, AIME\n",
      "      2024 = 13.3. o1-preview, Method = -. o1-preview, MATH500 = 87.0. o1-preview,\n",
      "      AIME 2024 = 40.0. Claude3.5-Sonnet, Method = -. Claude3.5-Sonnet, MATH500 =\n",
      "      78.3. Claude3.5-Sonnet, AIME 2024 = 16.0. Open-Source LLMs, Method = . Open-\n",
      "      Source LLMs, MATH500 = . Open-Source LLMs, AIME 2024 = . Llama-3.1-70B-Instruct,\n",
      "      Method = -. Llama-3.1-70B-Instruct, MATH500 = 65.7. Llama-3.1-70B-Instruct, AIME\n",
      "      2024 = 16.6. Qwen2.5-Math-72B-Instruct, Method = -. Qwen2.5-Math-72B-Instruct,\n",
      "      MATH500 = 82.0. Qwen2.5-Math-72B-Instruct, AIME 2024 = 30.0. Open-Source SLMs,\n",
      "      Method = . Open-Source SLMs, MATH500 = . Open-Source SLMs, AIME 2024 = .\n",
      "      Llama-3.2-1B-Instruct, Method = Pass@1. Llama-3.2-1B-Instruct, MATH500 = 26.8.\n",
      "      Llama-3.2-1B-Instruct, AIME 2024 = 0.0. , Method = BoN. , MATH500 = 46.6. , AIME\n",
      "      2024 = 3.3. , Method = WBoN. , MATH500 = 47.8. , AIME 2024 = 3.3. , Method =\n",
      "      DVTS. , MATH500 = 52.8. , AIME 2024 = 6.6. , Method = Ours - PF. , MATH500 =\n",
      "      59.6. , AIME 2024 = 10.0. Llama-3.1-8B-Instruct, Method = Pass@1.\n",
      "    questions_and_answers:\n",
      "      - question: What is the MATH500 score for GPT-4o?\n",
      "        answer: '76.2'\n",
      "      - question: |-\n",
      "          Which models have a higher AIME 2024 score: GPT-4o, o1-preview,\n",
      "          Claude3.5-Sonnet, Llama-3.1-70B-Instruct, Qwen2.5-Math-72B-Instruct, or\n",
      "          Llama-3.2-1B-Instruct?\n",
      "        answer: |-\n",
      "          Qwen2.5-Math-72B-Instruct has the highest AIME 2024 score among the mentioned\n",
      "          models.\n",
      "  - context: |-\n",
      "      Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker, B., Lee, T., Leike, J., Schulman, J., Sutskever, I., and Cobbe, K. Let's verify step by step, 2023b. URL https: //arxiv.org/abs/2305.20050 .\n",
      "      Loula, J., LeBrun, B., Du, L., Lipkin, B., Pasti, C., Grand, G., Liu, T., Emara, Y., Freedman, M., Eisner, J., Cotterell, R., Mansinghka, V., Lew, A. K., Vieira, T., and O'Donnell, T. J. Syntactic and semantic control of large language models via sequential monte carlo. In The Thirteenth International Conference on Learning Representations , 2025. URL https://openreview.net/ forum?id=xoXn62FzD0 .\n",
      "      MacKay, D. J. Information theory, inference and learning algorithms . Cambridge university press, 2003.\n",
      "      Moral, P. D. Sequential Monte Carlo Methods for Dynamic Systems: Journal of the American Statistical Association: Vol 93, No 443. https://www.tandfonline.com/doi/abs/10.1080/01621459.1998.10473765, 1997.\n",
      "      Murphy, K. P. Machine learning: a probabilistic perspective . MIT press, 2012.\n",
      "    questions_and_answers:\n",
      "      - question: |-\n",
      "          Who is one of the authors of the paper 'Syntactic and semantic control of large\n",
      "          language models via sequential monte carlo'?\n",
      "        answer: Loula, J.\n",
      "      - question: |-\n",
      "          If a language model is trained on a large corpus of text, could it be said to\n",
      "          have 'learned' the statistics of the language? Why or why not?\n",
      "        answer: |-\n",
      "          Yes, according to the probabilistic perspective of machine learning, a language\n",
      "          model can be seen as having 'learned' the statistics of the language, as it\n",
      "          learns the probability distribution of the next word given the previous words.\n",
      "          This is evident in the 'Machine learning: a probabilistic perspective' book by\n",
      "          Kevin P. Murphy.\n",
      "  - context: |-\n",
      "      3. We study ways to use PRMs and propose a more robust and performant way to obtain rewards for partial answers which we refer to as model-based aggregation.\n",
      "      4. We demonstrate that the proposed methods have 416x faster scaling speed than previous methods based on a search formulation on the MATH500 and AIME 2024 datasets, with small language models in the Llama and Qwen families. We show that PF can scale Qwen2.5-Math-1.5B-Instruct to surpasses GPT-4o accuracy with only a budget of 4 and scale Qwen2.5Math-7B-Instruct to o1 accuracy with a budget of 32.\n",
      "    questions_and_answers:\n",
      "      - question: |-\n",
      "          How many times faster is the scaling speed of the proposed methods compared to\n",
      "          previous methods?\n",
      "        answer: 416x\n",
      "      - question: |-\n",
      "          What are the two datasets used to demonstrate the performance of the proposed\n",
      "          methods and what are the two families of language models used?\n",
      "        answer: |-\n",
      "          The two datasets used are MATH500 and AIME 2024, and the two families of\n",
      "          language models used are Llama and Qwen.\n",
      "      - question: |-\n",
      "          Based on the provided context, if you were to scale Qwen2.5-Math-1.5B-Instruct\n",
      "          to surpass GPT-4's accuracy with the lowest possible budget, what would that\n",
      "          budget be?\n",
      "        answer: The budget would be 4.\n",
      "document_outline: |-\n",
      "  A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using\n",
      "  Particle-Based Monte Carlo Methods\n",
      "domain: artificial intelligence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(qna_output_path) as yaml_file:\n",
    "    print(yaml_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c574f96-5860-48b9-b4ac-01d367c7717b",
   "metadata": {},
   "source": [
    "### Revise QAs\n",
    "\n",
    "Open the generated `qna.yaml` in your preferred text editor to ensure the quality of generated questions and answers. If the generation step has failed to generated three questions and answers for each of five contexts, supplant until that required number of QA pairs is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f101076-a50f-49ea-a83b-46eaa8b39cc4",
   "metadata": {},
   "source": [
    "## Create Seed Dataset for SDG\n",
    "\n",
    "This section combines the contents from the qna.yaml and the chunks from the source document to create a seed dataset for the synthetic data generation process.\n",
    "\n",
    "To run this step you need a directory that contains `chunks.jsonl` and a `qna.yaml` in the same directory.\n",
    "\n",
    "This step outputs a seed.jsonl file in the SDG_OUTPUT_DIR that you set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2c6e31b-e8a9-406c-b2dc-27433c8fd8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab2c9ed2-8ba8-4959-8e01-81625b81d286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31028b6a6e894b55bdd91b429008b591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412be6db8f3b4d259bdd6ed8f9314bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e7f91dc8454798bfc61d605a62703a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388343b9ee474bccb65cdb92b016d4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33638125f9bb48f39a92e66b80d244bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd66034f06d408a897b5d494f2f67c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922a16c14b1f4079963e90924419b301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc2d4695b7146dc9595ce1a595930d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2222bfef0734126939deb3b9811f227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f946dae206564cf985ca682f8c76b103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de809767e5754a87aacf4d12211d2086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35f364424c54c5b97b0086c0c8a358f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f604fd38eb4212ab3679be71c15ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8461ee8d54e456b83365ef02bb3d1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc7688505864e59ac9cb62a6606811b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ac4b36c760468c9d56816befa89ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c9085ac2ae4ca2b9ed499230d3a520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa1805692424d138c6b4e31f3c0b9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae5908940d54fa8a7ffd79080e14057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f80bb4ddec41da9ba2377f0ca724a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615184103ca2452b844bdd7058cf74d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bd1643e1dc42cbbceb1e40782bec73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18813affd53f4f44961bacea83d577ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709446274b054d488d824f061f451d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dffa1a44904499198816aea085755c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a538c0f64240faab131dc0bffdaf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9fb179536c483ca346aed2b7d06048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe4f3e4db40492b8107ca012d2170b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2244a016bfb4e93bd625894b88e91ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c109b96f4414670b1427761182f1faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6da7ff38f045419dc6213f6f1ff2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309b9ffca00f4371b015dad9757f9005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287e2af7ed854ac1bbdbd828f1a3fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76e59d35c194112a695449960a7a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2917e685e54e42a1df162c4d26bb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c2b9cf31304be0a78bb83ccef412f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedfc205063a4f748d2f003d549db666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed data contains 18600 rows\n",
      "Results saved to: workspaces/default/sdg/seed_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "from utils.create_seed_dataset import get_seed_dataset\n",
    "\n",
    "seed_data = get_seed_dataset(CHUNKING_OUTPUT_DIR, AUTHORING_OUTPUT_DIR)\n",
    "output_path = f'{SDG_OUTPUT_DIR}/seed_data.jsonl'\n",
    "seed_data.to_json(output_path, orient='records', lines=True)\n",
    "\n",
    "print(f\"Seed data contains {seed_data.data.num_rows} rows\")\n",
    "print(f\"Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff36f4-19fc-4a27-b51a-3688e7b630e4",
   "metadata": {},
   "source": [
    "### Inspect the seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6936825-31c1-4b46-a1af-2fb46f50158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "document_outline: string\n",
      "document_title: string\n",
      "domain: string\n",
      "icl_document: string\n",
      "icl_query_1: string\n",
      "icl_response_1: string\n",
      "icl_query_2: string\n",
      "icl_response_2: string\n",
      "icl_query_3: string\n",
      "icl_response_3: string\n",
      "document: string\n",
      "----\n",
      "document_outline: [[\"A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using\n",
      "Particle-Based Monte Carlo Methods\"]]\n",
      "document_title: [[\"2022-nfl-rulebook-final\"]]\n",
      "domain: [[\"artificial intelligence\"]]\n",
      "icl_document: [[\"ARTICLE 1.  GENERAL POLICY. Throughout the game-day period while in view of the stadium and television audience, including during team pregame warm-ups, all players must dress in a professional manner under the uniform standards. The helmet and mandatory padding referenced in Article 3 below are intended to provide reasonable protection to a player while reasonably avoiding risk of injury to other players. The development of Playing Rules should be governed by this Article. Players generally must present an appearance that is appropriate to representing their individual clubs and the National Football League. The term uniform, as used in this policy, applies to every piece of equipment worn by a player, including helmet, shoulder pads, thigh pads, knee pads, and any other item of protective gear, and to every visible item of apparel, including but not limited to pants, jerseys, wristbands, gloves, game socks and/or leg coverings, shoes, visible undergarments, and accessories such as headwear worn under helmets and hand towels. All visible items worn on game day by players must be issued by the club or the League, or, if from outside sources, must have approval in advance by the League office.\n",
      "ARTICLE 2.  TEAM COLORS. Pursuant to the official colors established for each NFL club in the League Constitution and Bylaws, playing squads are permitted to wear only those colors or a combination of those colors for helmets, jerseys, pants, and game socks and/or leg coverings; provided that white is also an available color for jerseys and mandatory color for the lower portion of game socks and/or leg coverings. (See 5-4-3-Item 6, 'Game socks and/or leg coverings,' below). Each player on a given team must wear the same colors on his uniform as all other players on his team in the same game. Home clubs shall choose their jersey color (either white or official team color), and visiting clubs must wear the opposite. For preseason, regular season, or postseason\"]]\n",
      "icl_query_1: [[\"What is the mandatory color for the lower portion of game socks and/or leg\n",
      "coverings?\"]]\n",
      "icl_response_1: [[\"White\"]]\n",
      "icl_query_2: [[\"What are the color options for a player's uniform, including helmets, jerseys,\n",
      "pants, and game socks and/or leg coverings?\"]]\n",
      "icl_response_2: [[\"Players are permitted to wear only the colors or a combination of those colors\n",
      "established for their NFL club in the League Constitution and Bylaws, with white\n",
      "also being an available color for jerseys and mandatory for the lower portion of\n",
      "game socks and/or leg coverings. Each player on a given team must wear the same\n",
      "colors on his uniform as all other players on his team in the same game.\"]]\n",
      "icl_query_3: [[\"Based on the policy, why is it important for players to present an appearance\n",
      "that is appropriate to representing their individual clubs and the National\n",
      "Football League?\"]]\n",
      "icl_response_3: [[\"The policy emphasizes professionalism and representation, suggesting that the\n",
      "appearance of players reflects on both their individual clubs and the league as\n",
      "a whole. Therefore, maintaining an appropriate appearance is important for\n",
      "upholding the image and reputation of both the club and the league.\"]]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(seed_data.data.table.slice(length=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8fcdb-8035-4f30-b856-46afe9f928a1",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "To recap, given a source document in PDF format, this notebook:\n",
    "\n",
    "1. Converted the document using document and saved it to JSON for inspection\n",
    "2. Split the extracted text into chunks\n",
    "3. Generated QA pairs for a subset of those chunks\n",
    "4. Created a `qna.yaml` available for inspection and revision\n",
    "5. Combined the chunks and `qna.yaml` to create a `seed_data.jsonl` for use with SDG\n",
    "\n",
    "The next step is to use the resulting `seed_data.jsonl` for SDG, such as illustrated in [this notebook](https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub/blob/main/examples/instructlab/knowledge/knowledge_generation_and_mixing.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
