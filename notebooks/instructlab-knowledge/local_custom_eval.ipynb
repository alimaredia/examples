{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bb24d2-f2f7-455f-8854-6d1ae1f233b8",
   "metadata": {},
   "source": [
    "# Custom evaluations of the fine tuned model locally\n",
    "\n",
    "After fine tuning and deploying your model for testing, you can compare it to the accuracy and faithfulness of responses from other models in RAG based systems.  If you'd like to compare your model to others and see how it performs, this notebook will help you do that.\n",
    "\n",
    "NOTE: If you'd like to do a standard evaluation using the llm-eval-app service, use the `eval_rh_api.ipynb` notebook.\n",
    "\n",
    "To prepare for the evaluation, you will need to have the following:\n",
    "1. A set of models deployed and accessible via an API.\n",
    "2. A config.yaml file with the model information.\n",
    "3. A set of reference questions and answers in a common format (csv, jsonl, or qna.yaml).\n",
    "4. A set of context data in PDF format.  These are generally the documents that the model was trained on.\n",
    "\n",
    "The process involves the following steps:\n",
    "1. Sanity check the models to ensure your configuration is working correctly.\n",
    "2. Generate reference questions and answers from the `reference_answers` directory.\n",
    "3. Generate sample context data using a Milvus Lite Vector DB and the PDFs in the `data_preparation/document_collection` directory.\n",
    "4. Get responses from each of the available models.\n",
    "5. Grade responses using InstructLab.\n",
    "6. Grade responses using OpenAI ChatGPT-4o as a Judge Model.\n",
    "7. Save the results and create a resulting score report in Excel, Markdown, and HTML.\n",
    "\n",
    "By the end of the notebook, you will have json file with the evaluation and a summary of the evaluation results in an Excel, Markdown, and HTML.\n",
    "\n",
    "#### Summary\n",
    "| question index   |   lab-tuned-granite |   lab-tuned-granite-rag |   granite-3.0-8b-instruct-rag |   gpt-4-rag |\n",
    "|:-----------------|--------------------:|------------------------:|------------------------------:|------------:|\n",
    "| Q1               |                   4 |                       5 |                             5 |     4       |\n",
    "| Q2               |                   1 |                       5 |                             5 |     5       |\n",
    "| ...              |                 ... |                     ... |                           ... |   ...       |\n",
    "| QX               |                   4 |                       5 |                             5 |     5       |\n",
    "| Sum              |                   9 |                      15 |                            15 |    14       |\n",
    "| Average          |                   3 |                       5 |                             5 |     4.66667 |\n",
    "\n",
    "\n",
    "#### lab-tuned-granite\n",
    "| user_input | reference | retrieved_context |  response |   score |     reasoning |\n",
    "|:-----------|----------:|------------------:|----------:|--------:|--------------:|\n",
    "| What is ...| It is...  | There is ...      | It is...  |  4      | The answer... |\n",
    "\n",
    "#### lab-tuned-granite-rag\n",
    "| user_input | reference | retrieved_context |  response |   score |     reasoning |\n",
    "|:-----------|----------:|------------------:|----------:|--------:|--------------:|\n",
    "| What is ...| It is...  | There is ...      | It is...  |  4      | The answer... |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b229-b520-4e82-a783-eb921bb955e7",
   "metadata": {},
   "source": [
    "### Needed packages and imports\n",
    "\n",
    "The following packages are needed to run the evaluation service.  If you have not already installed them, you can do so by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting instructlab==0.22.1 (from -r requirements.txt (line 1))\n",
      "  Using cached instructlab-0.22.1-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting docling==2.8.3 (from -r requirements.txt (line 2))\n",
      "  Using cached docling-2.8.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting einops==0.8.0 (from -r requirements.txt (line 3))\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting langchain==0.3.12 (from -r requirements.txt (line 4))\n",
      "  Using cached langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.3.12 (from -r requirements.txt (line 5))\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core==0.3.25 (from -r requirements.txt (line 6))\n",
      "  Using cached langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-milvus==0.1.7 (from -r requirements.txt (line 7))\n",
      "  Using cached langchain_milvus-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-openai==0.2.12 (from -r requirements.txt (line 8))\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-text-splitters==0.3.3 (from -r requirements.txt (line 9))\n",
      "  Using cached langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-anthropic (from -r requirements.txt (line 10))\n",
      "  Using cached langchain_anthropic-0.3.13-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting openai==1.57.4 (from -r requirements.txt (line 11))\n",
      "  Using cached openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pymilvus==2.5.0 (from -r requirements.txt (line 12))\n",
      "  Using cached pymilvus-2.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 13))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting sentence-transformers==3.3.1 (from -r requirements.txt (line 14))\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch==2.4.1 (from -r requirements.txt (line 15))\n",
      "  Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19.1 (from -r requirements.txt (line 16))\n",
      "  Using cached torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Collecting ragas==0.2.11 (from -r requirements.txt (line 17))\n",
      "  Using cached ragas-0.2.11-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting click-didyoumean>=0.3.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting datasets>=2.18.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting gguf>=0.6.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting GitPython>=3.1.42 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./venv/lib/python3.11/site-packages (from instructlab==0.22.1->-r requirements.txt (line 1)) (0.28.1)\n",
      "Collecting instructlab-eval<0.5.0,>=0.4.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_eval-0.4.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting instructlab-quantize>=0.1.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_quantize-0.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting instructlab-schema>=0.4.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_schema-0.4.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting instructlab-sdg<0.7.0,>=0.6.2 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_sdg-0.6.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting instructlab-training<0.7.0,>=0.6.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_training-0.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting llama_cpp_python==0.2.79 (from llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached llama_cpp_python-0.2.79-cp311-cp311-macosx_15_0_arm64.whl\n",
      "Collecting mlx<0.6.0,>=0.5.1 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached mlx-0.5.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting peft>=0.9.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.38 in ./venv/lib/python3.11/site-packages (from instructlab==0.22.1->-r requirements.txt (line 1)) (3.0.51)\n",
      "Collecting pydantic>=2.7.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting pydantic_yaml>=1.2.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_yaml-1.4.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./venv/lib/python3.11/site-packages (from instructlab==0.22.1->-r requirements.txt (line 1)) (6.0.2)\n",
      "Collecting rich>=13.3.1 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rouge-score>=0.1.2 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting ruamel.yaml>=0.17.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting tokenizers>=0.11.1 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting toml>=0.10.2 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm>=4.66.2 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers>=4.41.2 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting trl>=0.9.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting wandb>=0.16.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached wandb-0.19.11-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting xdg-base-dirs>=6.0.1 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached xdg_base_dirs-6.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: psutil>=6.0.0 in ./venv/lib/python3.11/site-packages (from instructlab==0.22.1->-r requirements.txt (line 1)) (7.0.0)\n",
      "Collecting huggingface_hub>=0.1.8 (from huggingface_hub[hf_transfer]>=0.1.8->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./venv/lib/python3.11/site-packages (from docling==2.8.3->-r requirements.txt (line 2)) (4.13.4)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in ./venv/lib/python3.11/site-packages (from docling==2.8.3->-r requirements.txt (line 2)) (2025.4.26)\n",
      "Collecting deepsearch-glm<0.27.0,>=0.26.1 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached deepsearch_glm-0.26.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (10 kB)\n",
      "Collecting docling-core<3.0.0,>=2.6.1 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Downloading docling_core-2.30.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting docling-ibm-models<3.0.0,>=2.0.6 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached docling_ibm_models-2.0.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting docling-parse<3.0.0,>=2.0.5 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached docling_parse-2.1.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting easyocr<2.0,>=1.7 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting lxml<6.0.0,>=4.0.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached lxml-5.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
      "Collecting marko<3.0.0,>=2.1.2 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached marko-2.1.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.1.5 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pandas<3.0.0,>=2.1.4 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pydantic>=2.7.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdfium2<5.0.0,>=4.30.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.2 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.2 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./venv/lib/python3.11/site-packages (from docling==2.8.3->-r requirements.txt (line 2)) (2.32.3)\n",
      "Collecting rtree<2.0.0,>=1.3.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached rtree-1.4.0-py3-none-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting scipy<2.0.0,>=1.6.0 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached scipy-1.15.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting typer<0.13.0,>=0.12.5 (from docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached aiohttp-3.11.18-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.12->-r requirements.txt (line 5))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.12->-r requirements.txt (line 5))\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.25->-r requirements.txt (line 6))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core==0.3.25->-r requirements.txt (line 6))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.11/site-packages (from langchain-core==0.3.25->-r requirements.txt (line 6)) (4.13.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->-r requirements.txt (line 8))\n",
      "  Using cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai==1.57.4->-r requirements.txt (line 11)) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.57.4->-r requirements.txt (line 11))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.57.4->-r requirements.txt (line 11))\n",
      "  Using cached jiter-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai==1.57.4->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: setuptools>69 in ./venv/lib/python3.11/site-packages (from pymilvus==2.5.0->-r requirements.txt (line 12)) (78.1.0)\n",
      "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus==2.5.0->-r requirements.txt (line 12))\n",
      "  Using cached grpcio-1.67.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting protobuf>=3.20.0 (from pymilvus==2.5.0->-r requirements.txt (line 12))\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting ujson>=2.0.0 (from pymilvus==2.5.0->-r requirements.txt (line 12))\n",
      "  Using cached ujson-5.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus==2.5.0->-r requirements.txt (line 12))\n",
      "  Using cached milvus_lite-2.4.12-py3-none-macosx_11_0_arm64.whl.metadata (10.0 kB)\n",
      "Collecting scikit-learn (from sentence-transformers==3.3.1->-r requirements.txt (line 14))\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting Pillow (from sentence-transformers==3.3.1->-r requirements.txt (line 14))\n",
      "  Using cached pillow-11.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting filelock (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sympy (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch==2.4.1->-r requirements.txt (line 15)) (3.1.6)\n",
      "Collecting fsspec (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.11/site-packages (from ragas==0.2.11->-r requirements.txt (line 17)) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.2.11->-r requirements.txt (line 17))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas==0.2.11->-r requirements.txt (line 17))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting uvicorn>=0.22.0 (from llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fastapi>=0.100.0 (from llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached sse_starlette-2.3.5-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting starlette-context<0.4,>=0.3.6 (from llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached starlette_context-0.3.6-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting anthropic<1,>=0.51.0 (from langchain-anthropic->-r requirements.txt (line 10))\n",
      "  Using cached anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-anthropic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-anthropic (from -r requirements.txt (line 10))\n",
      "  Downloading langchain_anthropic-0.3.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.11-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_anthropic-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./venv/lib/python3.11/site-packages (from langchain-anthropic->-r requirements.txt (line 10)) (0.7.1)\n",
      "INFO: pip is still looking at multiple versions of langchain-anthropic to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_anthropic-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_anthropic-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_anthropic-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_anthropic-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_anthropic-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached frozenlist-1.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached multidict-6.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.57.4->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling==2.8.3->-r requirements.txt (line 2)) (2.7)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12->-r requirements.txt (line 5))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12->-r requirements.txt (line 5))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting docutils!=0.21 (from deepsearch-glm<0.27.0,>=0.26.1->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rich>=13.3.1 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate>=0.8.9 (from deepsearch-glm<0.27.0,>=0.26.1->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in ./venv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2)) (4.23.0)\n",
      "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers==3.3.1->-r requirements.txt (line 14))\n",
      "  Using cached pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<3.0.0,>=2.0.6->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66 (from docling-ibm-models<3.0.0,>=2.0.6->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting scikit-image (from easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached scikit_image-0.25.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached python_bidi-0.6.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting Shapely (from easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached shapely-2.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pyclipper (from easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached pyclipper-1.3.0.post6-cp311-cp311-macosx_10_9_universal2.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata (5.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1.42->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->instructlab==0.22.1->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->instructlab==0.22.1->-r requirements.txt (line 1)) (0.16.0)\n",
      "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]>=0.1.8->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "Collecting shortuuid (from instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting accelerate (from instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pandas-stubs (from instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pandas_stubs-2.2.3.250308-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lm-eval>=0.4.4 (from instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n",
      "Collecting yamllint>=1.35.1 (from instructlab-schema>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached yamllint-1.37.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting datasets>=2.18.0 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting multiprocess (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec (from torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting wheel>=0.43 (from instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting py-cpuinfo (from instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting numba (from instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Collecting instructlab-dolomite>=0.2.0 (from instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached instructlab_dolomite-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting aiofiles>=23.2.1 (from instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch==2.4.1->-r requirements.txt (line 15)) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.25->-r requirements.txt (line 6)) (3.0.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.12->-r requirements.txt (line 4))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.5->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling==2.8.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0.0,>=2.1.4->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.1.4->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting safetensors (from peft>=0.9.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt-toolkit>=3.0.38->instructlab==0.22.1->-r requirements.txt (line 1)) (0.2.13)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.7.4->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.3.0->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->docling==2.8.3->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->docling==2.8.3->-r requirements.txt (line 2)) (2.4.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.3.1->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich>=13.3.1->instructlab==0.22.1->-r requirements.txt (line 1)) (2.19.1)\n",
      "Collecting absl-py (from rouge-score>=0.1.2->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nltk (from rouge-score>=0.1.2->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in ./venv/lib/python3.11/site-packages (from rouge-score>=0.1.2->instructlab==0.22.1->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached ruamel.yaml.clib-0.2.12-cp311-cp311-macosx_13_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.2.12->-r requirements.txt (line 8))\n",
      "  Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "INFO: pip is looking at multiple versions of trl to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting trl>=0.9.4 (from instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached trl-0.16.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.5->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.16.4->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.11/site-packages (from wandb>=0.16.4->instructlab==0.22.1->-r requirements.txt (line 1)) (4.3.8)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.16.4->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached sentry_sdk-2.28.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb>=0.16.4->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached setproctitle-1.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers==3.3.1->-r requirements.txt (line 14))\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==3.3.1->-r requirements.txt (line 14))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1->-r requirements.txt (line 15))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tesserocr<3.0.0,>=2.7.1 (from docling[tesserocr]<=2.8.3,>=2.4.2->instructlab-sdg<0.7.0,>=0.6.2->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tesserocr-2.8.0-cp311-cp311-macosx_15_0_arm64.whl.metadata (10 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.100.0->llama_cpp_python[server]==0.2.79->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.42->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling==2.8.3->-r requirements.txt (line 2)) (0.24.0)\n",
      "Collecting evaluate (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting numexpr (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached numexpr-2.10.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting pybind11>=2.6.2 (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pytablewriter (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting sacrebleu>=1.5.0 (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting sqlitedict (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached sqlitedict-2.1.0-py3-none-any.whl\n",
      "Collecting tqdm-multiprocess (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting zstandard (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting word2number (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached word2number-1.1-py3-none-any.whl\n",
      "Collecting more_itertools (from lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.3.1->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12->-r requirements.txt (line 5))\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.5.3 (from yamllint>=1.35.1->instructlab-schema>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets>=2.18.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->instructlab-training<0.7.0,>=0.6.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting types-pytz>=2022.1.1 (from pandas-stubs->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached types_pytz-2025.2.0.20250326-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr<2.0,>=1.7->docling==2.8.3->-r requirements.txt (line 2))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting colorama (from sacrebleu>=1.5.0->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval>=0.4.4->instructlab-eval<0.5.0,>=0.4.0->instructlab==0.22.1->-r requirements.txt (line 1))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Using cached instructlab-0.22.1-py3-none-any.whl (236 kB)\n",
      "Using cached docling-2.8.3-py3-none-any.whl (93 kB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_milvus-0.1.7-py3-none-any.whl (23 kB)\n",
      "Using cached langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "Using cached langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
      "Using cached openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "Using cached pymilvus-2.5.0-py3-none-any.whl (212 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "Using cached torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Using cached ragas-0.2.11-py3-none-any.whl (176 kB)\n",
      "Downloading langchain_anthropic-0.3.0-py3-none-any.whl (22 kB)\n",
      "Using cached aiohttp-3.11.18-cp311-cp311-macosx_11_0_arm64.whl (457 kB)\n",
      "Using cached anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
      "Using cached click-8.2.0-py3-none-any.whl (102 kB)\n",
      "Using cached click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached deepsearch_glm-0.26.2-cp311-cp311-macosx_14_0_arm64.whl (5.9 MB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docling_core-2.30.1-py3-none-any.whl (142 kB)\n",
      "Using cached docling_ibm_models-2.0.8-py3-none-any.whl (65 kB)\n",
      "Using cached docling_parse-2.1.2-cp311-cp311-macosx_14_0_arm64.whl (21.9 MB)\n",
      "Using cached easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached gguf-0.16.3-py3-none-any.whl (94 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached grpcio-1.67.1-cp311-cp311-macosx_10_9_universal2.whl (11.0 MB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "Using cached instructlab_eval-0.4.2-py3-none-any.whl (66 kB)\n",
      "Using cached instructlab_quantize-0.1.0-py3-none-any.whl (2.0 MB)\n",
      "Using cached instructlab_schema-0.4.2-py3-none-any.whl (18 kB)\n",
      "Using cached instructlab_sdg-0.6.3-py3-none-any.whl (78 kB)\n",
      "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached instructlab_training-0.6.1-py3-none-any.whl (53 kB)\n",
      "Using cached jiter-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (320 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Using cached lxml-5.4.0-cp311-cp311-macosx_10_9_universal2.whl (8.1 MB)\n",
      "Using cached marko-2.1.3-py3-none-any.whl (42 kB)\n",
      "Using cached milvus_lite-2.4.12-py3-none-macosx_11_0_arm64.whl (17.4 MB)\n",
      "Using cached mlx-0.5.1-cp311-cp311-macosx_14_0_arm64.whl (32.9 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Downloading protobuf-6.31.0-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached pydantic_yaml-1.4.0-py3-none-any.whl (17 kB)\n",
      "Using cached pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached rtree-1.4.0-py3-none-macosx_11_0_arm64.whl (439 kB)\n",
      "Using cached ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "Using cached scipy-1.15.3-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached ujson-5.10.0-cp311-cp311-macosx_11_0_arm64.whl (51 kB)\n",
      "Using cached wandb-0.19.11-py3-none-macosx_11_0_arm64.whl (20.4 MB)\n",
      "Using cached xdg_base_dirs-6.0.2-py3-none-any.whl (4.7 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached frozenlist-1.6.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached instructlab_dolomite-0.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Using cached jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Using cached latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
      "Using cached lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.4.3-cp311-cp311-macosx_11_0_arm64.whl (37 kB)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Using cached orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl (133 kB)\n",
      "Using cached propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl (30.9 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.12-cp311-cp311-macosx_13_0_arm64.whl (132 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached sentry_sdk-2.28.0-py2.py3-none-any.whl (341 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sse_starlette-2.3.5-py3-none-any.whl (10 kB)\n",
      "Using cached starlette_context-0.3.6-py3-none-any.whl (12 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
      "Using cached yamllint-1.37.1-py3-none-any.whl (68 kB)\n",
      "Using cached yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl (279 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "Using cached pandas_stubs-2.2.3.250308-py3-none-any.whl (158 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyclipper-1.3.0.post6-cp311-cp311-macosx_10_9_universal2.whl (270 kB)\n",
      "Using cached python_bidi-0.6.6-cp311-cp311-macosx_11_0_arm64.whl (264 kB)\n",
      "Using cached scikit_image-0.25.2-cp311-cp311-macosx_12_0_arm64.whl (13.2 MB)\n",
      "Using cached setproctitle-1.3.6-cp311-cp311-macosx_11_0_arm64.whl (11 kB)\n",
      "Using cached shapely-2.1.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Using cached shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Using cached sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached tesserocr-2.8.0-cp311-cp311-macosx_15_0_arm64.whl (3.6 MB)\n",
      "Using cached tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "Using cached types_pytz-2025.2.0.20250326-py3-none-any.whl (10 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached numexpr-2.10.2-cp311-cp311-macosx_11_0_arm64.whl (134 kB)\n",
      "Using cached pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
      "Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
      "Using cached mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
      "Using cached pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
      "Using cached tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
      "Using cached typepy-1.3.4-py3-none-any.whl (31 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: word2number, tesserocr, sqlitedict, sentencepiece, pytz, python-bidi, pyclipper, py-cpuinfo, mpmath, filetype, appdirs, zstandard, xxhash, XlsxWriter, xdg-base-dirs, wheel, ujson, tzdata, typing-inspection, types-pytz, tqdm, toml, threadpoolctl, tenacity, tcolorpy, tabulate, sympy, SQLAlchemy, smmap, shortuuid, shellingham, setproctitle, sentry-sdk, safetensors, ruamel.yaml.clib, rtree, regex, python-dotenv, pypdfium2, pydantic-core, pybind11, pyarrow, protobuf, propcache, portalocker, Pillow, pathvalidate, pathspec, packaging, orjson, numpy, ninja, networkx, mypy-extensions, multidict, more_itertools, mlx, mdurl, marko, lxml, llvmlite, latex2mathml, jsonref, jsonpatch, jsonlines, joblib, jiter, instructlab-quantize, httpx-sse, hf-transfer, grpcio, fsspec, frozenlist, filelock, et-xmlfile, einops, docutils, docker-pycreds, distro, diskcache, dill, colorama, click, chardet, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yarl, yamllint, uvicorn, typing-inspect, tqdm-multiprocess, torch, tiktoken, tifffile, starlette, Shapely, scipy, sacrebleu, ruamel.yaml, requests-toolbelt, python-pptx, python-docx, pydantic, pandas-stubs, pandas, openpyxl, opencv-python-headless, numexpr, numba, nltk, multiprocess, milvus-lite, mbstrdecoder, marshmallow, markdown-it-py, llama_cpp_python, lazy-loader, imageio, huggingface_hub, gitdb, gguf, docling-parse, click-didyoumean, aiosignal, typepy, torchvision, tokenizers, starlette-context, sse-starlette, scikit-learn, scikit-image, rouge-score, rich, pymilvus, pydantic_yaml, pydantic-settings, openai, langsmith, GitPython, fastapi, dataclasses-json, anthropic, aiohttp, accelerate, wandb, typer, transformers, langchain-core, instructlab-schema, easyocr, docling-ibm-models, sentence-transformers, peft, langchain-text-splitters, langchain-openai, langchain-milvus, langchain-anthropic, instructlab-dolomite, docling-core, datasets, DataProperty, trl, tabledata, langchain, evaluate, deepsearch-glm, pytablewriter, langchain-community, instructlab-training, docling, ragas, lm-eval, instructlab-sdg, instructlab-eval, instructlab\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed DataProperty-1.1.0 GitPython-3.1.44 Pillow-10.4.0 SQLAlchemy-2.0.41 Shapely-2.1.0 XlsxWriter-3.2.3 absl-py-2.2.2 accelerate-1.6.0 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 anthropic-0.51.0 appdirs-1.4.4 chardet-5.2.0 click-8.2.0 click-didyoumean-0.3.1 colorama-0.4.6 dataclasses-json-0.6.7 datasets-2.21.0 deepsearch-glm-0.26.2 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 docker-pycreds-0.4.0 docling-2.8.3 docling-core-2.30.1 docling-ibm-models-2.0.8 docling-parse-2.1.2 docutils-0.21.2 easyocr-1.7.2 einops-0.8.0 et-xmlfile-2.0.0 evaluate-0.4.3 fastapi-0.115.12 filelock-3.18.0 filetype-1.2.0 frozenlist-1.6.0 fsspec-2024.6.1 gguf-0.16.3 gitdb-4.0.12 grpcio-1.67.1 hf-transfer-0.1.9 httpx-sse-0.4.0 huggingface_hub-0.31.2 imageio-2.37.0 instructlab-0.22.1 instructlab-dolomite-0.2.0 instructlab-eval-0.4.2 instructlab-quantize-0.1.0 instructlab-schema-0.4.2 instructlab-sdg-0.6.3 instructlab-training-0.6.1 jiter-0.9.0 joblib-1.5.0 jsonlines-3.1.0 jsonpatch-1.33 jsonref-1.1.0 langchain-0.3.12 langchain-anthropic-0.3.0 langchain-community-0.3.12 langchain-core-0.3.25 langchain-milvus-0.1.7 langchain-openai-0.2.12 langchain-text-splitters-0.3.3 langsmith-0.2.11 latex2mathml-3.78.0 lazy-loader-0.4 llama_cpp_python-0.2.79 llvmlite-0.44.0 lm-eval-0.4.8 lxml-5.4.0 markdown-it-py-3.0.0 marko-2.1.3 marshmallow-3.26.1 mbstrdecoder-1.1.4 mdurl-0.1.2 milvus-lite-2.4.12 mlx-0.5.1 more_itertools-10.7.0 mpmath-1.3.0 multidict-6.4.3 multiprocess-0.70.16 mypy-extensions-1.1.0 networkx-3.4.2 ninja-1.11.1.4 nltk-3.9.1 numba-0.61.2 numexpr-2.10.2 numpy-1.26.4 openai-1.57.4 opencv-python-headless-4.11.0.86 openpyxl-3.1.5 orjson-3.10.18 packaging-24.2 pandas-2.2.3 pandas-stubs-2.2.3.250308 pathspec-0.12.1 pathvalidate-3.2.3 peft-0.15.2 portalocker-3.1.1 propcache-0.3.1 protobuf-6.31.0 py-cpuinfo-9.0.0 pyarrow-20.0.0 pybind11-2.13.6 pyclipper-1.3.0.post6 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.9.1 pydantic_yaml-1.4.0 pymilvus-2.5.0 pypdfium2-4.30.1 pytablewriter-1.2.1 python-bidi-0.6.6 python-docx-1.1.2 python-dotenv-1.0.1 python-pptx-1.0.2 pytz-2025.2 ragas-0.2.11 regex-2024.11.6 requests-toolbelt-1.0.0 rich-13.9.4 rouge-score-0.1.2 rtree-1.4.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 sacrebleu-2.5.1 safetensors-0.5.3 scikit-image-0.25.2 scikit-learn-1.6.1 scipy-1.15.3 sentence-transformers-3.3.1 sentencepiece-0.2.0 sentry-sdk-2.28.0 setproctitle-1.3.6 shellingham-1.5.4 shortuuid-1.0.13 smmap-5.0.2 sqlitedict-2.1.0 sse-starlette-2.3.5 starlette-0.46.2 starlette-context-0.3.6 sympy-1.14.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 tenacity-9.1.2 tesserocr-2.8.0 threadpoolctl-3.6.0 tifffile-2025.5.10 tiktoken-0.9.0 tokenizers-0.21.1 toml-0.10.2 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.51.3 trl-0.15.2 typepy-1.3.4 typer-0.12.5 types-pytz-2025.2.0.20250326 typing-inspect-0.9.0 typing-inspection-0.4.0 tzdata-2025.2 ujson-5.10.0 uvicorn-0.34.2 wandb-0.19.11 wheel-0.45.1 word2number-1.1 xdg-base-dirs-6.0.2 xxhash-3.5.0 yamllint-1.37.1 yarl-1.20.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1140795af54d8",
   "metadata": {},
   "source": [
    "### Testing Configuration - `config.yaml`\n",
    "\n",
    "Before running the evaluation, you will need to create a `config.yaml` file with the model information.  There is [config_example.yaml](config_example.yaml) that has some <FIELDS> that need to be filled out, such as API Key, but you can use it to get started.\n",
    "\n",
    "The file should be in the following format:\n",
    "```yaml\n",
    "name: my-eval # this determines the output directory of the evaluation.\n",
    "judge:\n",
    "    model_name: gpt-4o # choose the best OpenAI model for judging the responses.\n",
    "    api_key: sk-12345  # OpenAI API Key is required to run the evaluations for both InstructLab and OpenAI\n",
    "    template: |        # This is the langchain scoring template for the judge model. It is used in the ChatGPT-4o model to score the responses. The InstructLab model uses its own scoring template.\n",
    "      Evaluate the answer_quality as:\n",
    "      - Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "      - Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "      ...\n",
    "testing_configs:\n",
    "  - name: lab-tuned-granite # this is a name for the testing configuration.  It also determines output file names.\n",
    "    endpoint_url: https://openai-api.com/v1 # The endpoint URL for the model. Ignore if using OpenAI. Don't forget /v1.\n",
    "    model_name: finetuned   # model name used by the OpenAI API. e.g. finetuned, gpt-4, etc.\n",
    "    model_type: vllm        # vllm/openai depending on the model type.  openai will ignore the endpoint_url\n",
    "    api_key: eyafsdasdfsdf  # API Key for the served model\n",
    "    rag: False              # Whether or not using RAG.  True if the template has context fields, False if it does not.\n",
    "    template: |\n",
    "      <|system|> I am a Red Hat Instruct Model\n",
    "      <|user|>\n",
    "      Answer the following question based on internal knowledge.\n",
    "      Question: {question}\n",
    "      Answer:\n",
    "      <|assistant|>\n",
    "  - name: gpt-4-rag\n",
    "    model_name: gpt-4\n",
    "    model_type: openai\n",
    "    api_key: SK-12345\n",
    "    rag: True\n",
    "    template: |\n",
    "      Context:\n",
    "      {context}\n",
    "      Answer the following question from the above context.\n",
    "      Question: {question}\n",
    "      Answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850fa004651738c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:52:20.509165Z",
     "start_time": "2025-02-05T18:52:20.501640Z"
    }
   },
   "outputs": [],
   "source": [
    "from eval_utils import get_config, check_judge_config, check_testing_config\n",
    "\n",
    "config = get_config()\n",
    "check_judge_config(config.get(\"judge\"))\n",
    "for testing_config in config.get(\"testing_configs\"):\n",
    "    check_testing_config(testing_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177bb49b96e57fe",
   "metadata": {},
   "source": [
    "## Sanity check models\n",
    "\n",
    "We will first test each of the models to ensure they are working correctly.  This will help us identify any issues with the configuration before running the evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4ccb5253478c0",
   "metadata": {},
   "source": [
    "#### Test Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c2ab24a267887b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:52:32.046902Z",
     "start_time": "2025-02-05T18:52:24.729482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "claude-3-7-sonnet\n",
      "Anthropic is here with model claude-3-7-sonnet-20250219\n",
      "Question: Who are you?? Answer: I'm Bob, a human. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import create_llm, chat_request, get_first_config\n",
    "\n",
    "for testing_config in config[\"testing_configs\"]:\n",
    "    print(\"-\" * 80)\n",
    "    print(testing_config.get(\"name\") or testing_config.get(\"model_name\"))\n",
    "    llm = create_llm(testing_config)\n",
    "    question = \"Who are you?\"\n",
    "    if testing_config.get(\"rag\"):\n",
    "        retrieved_context = \"Pretend to be a human named Bob\"\n",
    "    else:\n",
    "        retrieved_context = None\n",
    "    answer = chat_request(llm, testing_config.get(\"template\"), question, retrieved_context)\n",
    "    print(f\"Question: {question}? Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe9c8d763f89d3",
   "metadata": {},
   "source": [
    "## Generate Reference Data (Questions, Answers, and Context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf034e7474f5bf5",
   "metadata": {},
   "source": [
    "### Use qna.yaml, csv, jsonl to create some data\n",
    "\n",
    "Before creating a set of reference ansers in a common `jsonl` format, you must:\n",
    "\n",
    "1. Put your reference answers in the `reference_answers` directory\n",
    "2. Put any relevant source PDF documents in the `data_preparation/document_collection`.\n",
    "\n",
    "The reference answers should be in the format of a csv, jsonl, or a qna.yaml file.  It's preferable to use questions and reference answers made by human subject matter experts.  To this end CSV and jsonl files are easy formats to work with.  A qna.yaml file can also be added as an easy option.\n",
    "\n",
    "The CSV should be formatted with `user_input` and `reference` fields.\n",
    "| user_input | reference |\n",
    "|:-----------|----------:|\n",
    "| What is ...| It is...  |\n",
    "\n",
    "The JSONL should be formatted with `user_input` and `reference` fields.\n",
    "```json lines\n",
    "{\"user_input\": \"What is ...\", \"reference\": \"It is...\"}\n",
    "{\"user_input\": \"What is ...\", \"reference\": \"It is...\"}\n",
    "```\n",
    "\n",
    "The YAML file should be formatted with `seed_examples` and `questions_and_answers` fields.  This mirrors the normal `qna.yaml` format so that you can reuse the qna.yaml from your taxonomy.\n",
    "```yaml\n",
    "seed_examples:\n",
    "    questions_and_answers:\n",
    "      - question: >\n",
    "          relevant question?\n",
    "        answer: >\n",
    "          reference answer\n",
    "      - question: >\n",
    "          relevant question 2?\n",
    "        answer: >\n",
    "          reference answer 2\n",
    "```\n",
    "After transforming the data, we will write the data to a `jsonl` file and add a `retrieved_context` field to the data. A Milvus Lite Vector DB will be generated from the PDFs in `data_preparation/document_collection`.  The context will be retrieved from the document collection.\n",
    "\n",
    "At this point you can inspect the `results/reference_answers.jsonl` file to see the data and fix any issues you see, such as manually fixing the `retrieved_context` field before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0570b77dfc0d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T19:15:16.803993Z",
     "start_time": "2025-02-05T19:14:40.867561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_answers/knowledge/finance/banking/products/flexible_savings/qna.yaml: 16 questions\n",
      "reference_answers/knowledge/finance/banking/products/flexible_premier_checking/qna.yaml: 31 questions\n",
      "reference_answers/knowledge/finance/banking/products/flexible_money_market_savings/qna.yaml: 46 questions\n",
      "reference_answers/knowledge/finance/banking/products/flexible_core_checking/qna.yaml: 61 questions\n",
      "reference_answers/knowledge/finance/banking/products/flexible_enhanced_checking/qna.yaml: 77 questions\n",
      "reference_answers/knowledge/finance/banking/products/flexible_checking/qna.yaml: 92 questions\n",
      "reference_answers/knowledge/finance/banking/policies/qna.yaml: 107 questions\n",
      "reference_answers/knowledge/finance/banking/enablement/qna.yaml: 126 questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaredia/dev/rhel-ai-poc/eval/eval_utils.py:265: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e118c9bdd0e45d1a591c17a8a74c92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [create_index], <MilvusException: (code=65535, message=invalid index type: HNSW, local mode only support FLAT IVF_FLAT AUTOINDEX: )>, <Time:{'RPC start': '2025-05-14 16:58:14.762092', 'RPC error': '2025-05-14 16:58:14.762584'}>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 documents loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec80e405ed1c4b149c39414d81016c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059c6180356b432096088237d1f866c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e191a2ed55247bdae77a5200996496c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69a355f782f41af9f10138a9fb2783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6c105c3ebd47e9951873a2fc6388af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a404a4fa3b434d5fa1450f266a7f225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0245e946de94df8b09cf153d8c9ab72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41e633182614cefb2e490dc70239fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9010d4b3bfa44e87a531d38b5095ee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cf4ac3a0874badba40025413ca49c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18141a7b0b94cf192c0fa007f0b8860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7ac88f05014a09a0c4489a12d9d293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5132f93f97ba416a9b73c2e7a24dd240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b33357f6b4432c8314a9d54e42760e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaa8149b1ab41e2972286e732fe4f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf882e409d246f0bbb214b3baa775cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317ae08d9f14bb0a0be7bfd0fa656c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49004f1e3884225bf2ae430deb5c813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc0a39e4ece407a8d0174f88d56c7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90039e64b5c4443799ac1e743de53169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f146a5324544af8a183842797a712a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b94a545ca4a43b1a83914e823675207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3531eea9fa00432d8b0c194e05ddae37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500a1d18506b4dd3a51e62b7442f8e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddeefadc7ff40ce903bc35a078bb07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47d5b2043d74f32ab6c45528186297b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de9c1fbce7a4468b022883ab579f05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ca4aa42005439ba8dd163dd3ea1495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4915243bdee0434983b51a238d0e1b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5681dcacc4044aa9836ef348d1449354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1119cd02e08440eebc04d4e304bfdfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7192d867fb4e1ba26808754f316c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d293ec69a045ff9450e1eb7ba2c603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50f6ca3531c45fd806e7f524ba6400b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d42015ab3cf4d32896fe4578a90b204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3a9a48647342a1b0cd5e5944f71b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8234e66d3b4517b6586a22871946ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dceafdb1b34650bf06dc20b8c09af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7cde59fabb4eafb85d99c5d4412bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57327183090a41cca8772fb4e32c2151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6622219d140b4a9e95a4839ce87671c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476a327dcd9b46509f4601f401bc32c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f113a2fb50ba40f2858dd51f16d6b459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eab7c217dd7478ca966ef38c9a3f1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3528afe80b304b899ee60062d8b1e919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f515496f7a7411884298f721b89e101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b3bebc3b44fa9b4790ce6a1d92617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e045f41636cb40ecb053e1a22bdd3772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753ad67840b54e96981343ef2d9be598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ef0544dfdb47fdb29bb855fff30be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66830cda4fba4fd897e43cdddd3615fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc73660ec21e4964947f6ea2a7a8e359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a3b0487d824d94a8f320114882208b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c849bbd1ae5a43b09acdf06ca89aefc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd49f08a881e4f48b8e866dc4afb477e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2b9525e0e14da4bbb328b9c429d03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b374eef04a4c8fbaa90108e50f3ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828cc42b01314dd19049721bdffe96bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2da611e1dd14fe78479731dae5c74a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111ca113035d489b9a5340d07fc944a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec988cb1006348779653251358401d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307c253b944441aeac3b3bd894d20016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7570acff67147c1a3986f341df5ebf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6482d7debbe341769b2ea35215f5750e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb117541f64ce099cda9c995fbfdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38425d86d5548afa62488429fc264a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64c67273f941d2820abf55c228d8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd210d0b7a142679599c6d9309b7ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e127a6a65afa433c911de49816592c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e195be26c747fe9d7fb1ffd4c231b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e25ab37b1cd4a1caff48c0c4066365b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cffa24342c4ee08088d31f64ab8056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb20cece6f24f94becc3b159ba4cebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ff1ac7c99c4c0f855dc8077d456120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aefd7052e904cfa80bd5b4f0bea8978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d92cfd7cbb46dda18be9a491de80fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f05e3d4cb1d412db47f86a5b9b1de26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251b245af5a1416baf3aec96172daab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ab099e33cb4ed0a2b20c940da57272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d82e7c9366440099c6f9a9109cadb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e529ad26f314ea08e76cc7cb619fe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfe54b84a7c4f25b774fa5bd5019c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cb2b41951440ce8702d9bba79ed1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a61809e77340038d244ce9d7923f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132510fa34ba43c286f7a1726dbfa7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b7ce6ddab64163b9e36c74b0638d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b850701b78245878fd99809ae91ed88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb16f16aeb7449e2bd4a105bbe63ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef84e2a6ef49acb5b66b93e0dabb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604cc66adafb4d378ebc9f4af8741ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b4c995b91742a3bbb6ba2ac5e579c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349886c57c674d2e827a0acd52b956d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486560d6946c46ab9606532f4ad87874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e3819fc6444f978665fe64042b5eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dc4b0a6bd249f7b06e4864d3af1523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eeb10eacbc498aa3ab86dd44cd334f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1ac68be7a541759fad8931c429bcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902cdb8364934320b97ab266cb92c847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a38ed316fd44e7388b2e692fd1f3661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b48ed367b74b369358cccee7b56a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d6c779fa2646f1a49cca79682f4e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc86bf497a8480d998129e386d7229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c01b7fc59d4a99abdc80ecb9a0b4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f90de430074b55bc8fa2057f787a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388850e1068d408eaa9faf784f531d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21baf725446e4f14b8c0c50c1a3adbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593aefaf8f6a4eccbc50d15936a43043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c1a44998e440d89b4281a0e1adc256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defb2a184f72432fbb890a8e2e18ea85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be485fac59e461f8408cd7704d44bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccf1785c4e3426987cac7295ca5fe76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6446a039ea0461abdc8e67098e3d669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb78187958c14a5fbcd8891a98865c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5321393b02cd475b97f5cdb6c2fc40af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785ef0eb8c94bf2a5c7f300b591e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd3ee6d5c844149a3d0173e1715d015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6884858c0b2a4b6e82e0d9eda5828ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7495c4039d41e9afe752dc5590ecf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8201102fc191406aad35c0ff6791395f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe00bd51f8ff436986613c80be88f659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2b89efe1af4372ae56df98647d6216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c37fa1c91145ee89bb624f15a3f7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03de0a9839934141b0769a9314656677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2c6577af6c4ad5bad5af72751412fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94b2393f4214bbfab0ceffccda73ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c343f8d188c46ea97c06ab683fceabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 reference answers loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from eval_utils import get_output_dir, get_reference_answers, get_context, write_jsonl\n",
    "\n",
    "output_directory =  get_output_dir()\n",
    "reference_answers = get_reference_answers(\"./reference_answers\")\n",
    "reference_answers = get_context(reference_answers, \"../data_preparation/document_collection\")\n",
    "print(str(len(reference_answers)) + \" reference answers loaded\")\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "write_jsonl(f\"{output_directory}/reference_answers.jsonl\", reference_answers)\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cb58d65398ba",
   "metadata": {},
   "source": [
    "## Get responses from each of the available models\n",
    "\n",
    "Now that we have the `user_input`, `reference`, and `retrieved_context` fields in the `reference_answers.jsonl` file, we can get responses from each of the available models.  We will save the responses in a `responses` directory for each model.  The responses will be saved in a `jsonl` file with the format of `user_input`, `reference`, `retrieved_context`, and `response`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b82aa5d43363d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:58:28.394702Z",
     "start_time": "2025-02-05T20:58:28.383691Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from eval_utils import read_jsonl\n",
    "\n",
    "config = get_config()\n",
    "output_directory = get_output_dir()\n",
    "\n",
    "responses_directory = output_directory + \"/responses\"\n",
    "os.makedirs(responses_directory, exist_ok=True)\n",
    "\n",
    "reference_answers = read_jsonl(f\"{output_directory}/reference_answers.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318125c61600a8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T20:59:23.160091Z",
     "start_time": "2025-02-05T20:58:30.766801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "claude-3-7-sonnet\n",
      "Anthropic is here with model claude-3-7-sonnet-20250219\n",
      "Question 1: What is the monthly maintenance fee for \n",
      "Answer: Based on the context provided, the month\n",
      "Question 2: How can the monthly maintenance fee for \n",
      "Answer: Based on the context provided, the month\n",
      "Question 3: Is the Parasol Financial Flexible Saving\n",
      "Answer: Yes, the Parasol Financial Flexible Savi\n",
      "Question 4: How is interest calculated on the Paraso\n",
      "Answer: Based on the context provided, there is \n",
      "Question 5: What is extra interest?\n",
      "Answer: Based on the context provided, extra int\n",
      "Question 6: Where can I find current interest rate i\n",
      "Answer: You can find current interest rate infor\n",
      "Question 7: Does the Parasol Financial Flexible Savi\n",
      "Answer: Based on the context provided, it is sta\n",
      "Question 8: What happens if I don't have enough mone\n",
      "Answer: If you don't have enough money in your a\n",
      "Question 9: Can I be charged a fee by a merchant or \n",
      "Answer: Yes, you can be charged a fee by a merch\n",
      "Question 10: Are there any ATM fees for withdrawls fr\n",
      "Answer: Based on the context provided, there is \n",
      "Question 11: What are the ATM fees for a withdrawl fr\n",
      "Answer: Based on the context provided, the ATM f\n",
      "Question 12: What is the fee for a cashiers check for\n",
      "Answer: Based on the context provided, the fee f\n",
      "Question 13: What are the ATM fees for a withdrawal f\n",
      "Answer: For a withdrawal from a Non-Parasol Fina\n",
      "Question 14: What is the Penny Saved savings program?\n",
      "Answer: The Penny Saved savings program is an au\n",
      "Question 15: Can I make purchases with my debit card \n",
      "Answer: Yes, you can make purchases with your de\n",
      "Question 16: Where do the savings from the Penny Save\n",
      "Answer: Based on the context provided, the savin\n",
      "Question 17: What is the minimum amount when opening \n",
      "Answer: Based on the provided context, I cannot \n",
      "Question 18: Does this account type earn any interest\n",
      "Answer: Yes, this account type does earn interes\n",
      "Question 19: Is there an account monthly maintenance \n",
      "Answer: Yes, there are monthly maintenance fees \n",
      "Question 20: Is there a policy to help me avoid overd\n",
      "Answer: Yes, there is a policy to help you avoid\n",
      "Question 21: What are my options to elect for overdra\n",
      "Answer: Based on the context, you have two optio\n",
      "Question 22: If I don't pick an overdraft setting, wh\n",
      "Answer: If you don't pick an overdraft setting, \n",
      "Question 23: When will cash deposits be available?\n",
      "Answer: Based on the context provided, cash depo\n",
      "Question 24: When will check deposits be available?\n",
      "Answer: Based on the context provided, check dep\n",
      "Question 25: When will Mobile Check Deposits be avail\n",
      "Answer: Based on the context provided, Mobile Ch\n",
      "Question 26: Is there a specific number that I can ca\n",
      "Answer: Yes, there are specific numbers you can \n",
      "Question 27: Is there a website to review features an\n",
      "Answer: Yes, according to the context, you can r\n",
      "Question 28: How do you schedule an appointment with \n",
      "Answer: Based on the context provided, you can s\n",
      "Question 29: Are there any other fees for internation\n",
      "Answer: Yes, there are other fees for internatio\n",
      "Question 30: Do foreign taxes apply to international \n",
      "Answer: Based on the context provided, foreign t\n",
      "Question 31: Is there anything else to consider befor\n",
      "Answer: Yes, before sending an international wir\n",
      "Question 32: What is the monthly maintenance fee of t\n",
      "Answer: Based on the context provided, the month\n",
      "Question 33: How can you avoid the monthly maintenanc\n",
      "Answer: Based on the context provided, you can a\n",
      "Question 34: Is the Flexible Money Market Savings ins\n",
      "Answer: Yes, the Flexible Money Market Savings a\n",
      "Question 35: When are check deposits available on a R\n",
      "Answer: Based on the context provided, check dep\n",
      "Question 36: When are cash deposits available on a Re\n",
      "Answer: Based on the context provided, cash depo\n",
      "Question 37: When are mobile check deposits available\n",
      "Answer: Based on the context provided, mobile ch\n",
      "Question 38: What is the ATM fee for using Parasol Fi\n",
      "Answer: Based on the provided context, there is \n",
      "Question 39: What is the ATM fee for using Non-Paraso\n",
      "Answer: Based on the provided context, the ATM f\n",
      "Question 40: What is the fee for a cashier's check fr\n",
      "Answer: Based on the context provided, I see con\n",
      "Question 41: Where can I find the interest rate curre\n",
      "Answer: Based on the context provided, you can f\n",
      "Question 42: Is the interest rate on a Rewards Money \n",
      "Answer: Based on the context provided, the inter\n",
      "Question 43: How is the interest rate booster earned \n",
      "Answer: Based on the provided context, the inter\n",
      "Question 44: What is the overdraft item fee for the R\n",
      "Answer: Based on the provided context, there are\n",
      "Question 45: What is the maximum number of overdraft \n",
      "Answer: Based on the provided context, for the R\n",
      "Question 46: What is the Overdraft Protection Transfe\n",
      "Answer: Based on the provided context, the Overd\n",
      "Question 47: How much do I need to open a Core Checki\n",
      "Answer: Based on the context provided, you need \n",
      "Question 48: Is there a monthly maintenance fee for t\n",
      "Answer: Yes, there is a monthly maintenance fee \n",
      "Question 49: What are the ATM fees for use of Non-Par\n",
      "Answer: The ATM fees for use of Non-Parasol Fina\n",
      "Question 50: Are there bank overdraft fees on this ac\n",
      "Answer: Yes, there are bank overdraft fees on th\n",
      "Question 51: How soon are cash deposits available?\n",
      "Answer: Based on the context provided, cash depo\n",
      "Question 52: If my account has a negative balance wil\n",
      "Answer: Based on the context provided, if your a\n",
      "Question 53: What are the fees for a replacement card\n",
      "Answer: Based on the context provided, the fees \n",
      "Question 54: What is the fee for an International wir\n",
      "Answer: Based on the context provided, the fee f\n",
      "Question 55: Can Core Checking for Family Banking acc\n",
      "Answer: No, Core Checking for Family Banking acc\n",
      "Question 56: Where can I view all the features and be\n",
      "Answer: Based on the context, you can view all t\n",
      "Question 57: How can I schedule an appointment to vis\n",
      "Answer: Based on the context provided, you can s\n",
      "Question 58: What is the phone number to call Parasol\n",
      "Answer: Based on the provided context, the phone\n",
      "Question 59: What are the payment options for Parasol\n",
      "Answer: Based on the provided context, I cannot \n",
      "Question 60: Can I write a personal chack on my Paras\n",
      "Answer: Based on the provided context, I cannot \n",
      "Question 61: Does mobile banking require a mobile app\n",
      "Answer: Yes, mobile banking requires a mobile ap\n",
      "Question 62: What are the ATM fees for the Flexible E\n",
      "Answer: For the Parasol Financial Flexible Enhan\n",
      "Question 63: What is the opening deposit amount for t\n",
      "Answer: The opening deposit amount for the Paras\n",
      "Question 64: What is one way you avoid fees on a Flex\n",
      "Answer: One way to avoid fees on a Flexible Enha\n",
      "Question 65: Are there overdraft fees for the Parasol\n",
      "Answer: No, there are no overdraft fees for the \n",
      "Question 66: Will ATM withdrawals be authorized if th\n",
      "Answer: Based on the provided context, ATM withd\n",
      "Question 67: Will a scheduled payment be authorized i\n",
      "Answer: Based on the provided context, a schedul\n",
      "Question 68: What is the default setting for Overdraf\n",
      "Answer: Based on the context provided, the defau\n",
      "Question 69: What is overdraft setting option 1?\n",
      "Answer: Option 1 is the \"Standard\" overdraft set\n",
      "Question 70: What is the overdraft fee per item?\n",
      "Answer: Based on the context provided, the overd\n",
      "Question 71: Is there a overdraft item fee when optio\n",
      "Answer: No, there is no overdraft item fee when \n",
      "Question 72: What is overdraft setting option 2?\n",
      "Answer: Option 2 is \"Decline All\", which is a se\n",
      "Question 73: Is there a fee charged if a transaction \n",
      "Answer: According to the context, if the bank de\n",
      "Question 74: If I have selected the Decline All overd\n",
      "Answer: Based on the context, if you have select\n",
      "Question 75: What are the order of trasactions catego\n",
      "Answer: Based on the context provided, the order\n",
      "Question 76: Does the order transactions are posted i\n",
      "Answer: Yes, the order in which transactions are\n",
      "Question 77: Do transactions that are still processin\n",
      "Answer: Yes, transactions that are still process\n",
      "Question 78: Is the Flexible Core Checking account av\n",
      "Answer: Based on the context provided, it's not \n",
      "Question 79: What is the minimum balance required to \n",
      "Answer: The minimum daily balance required to av\n",
      "Question 80: What is the monthly maintenance fee for \n",
      "Answer: Based on the context provided, the month\n",
      "Question 81: Who is the target audience for the SafeB\n",
      "Answer: Based on the provided context, I don't s\n",
      "Question 82: What is the minimum balance for the Safe\n",
      "Answer: Based on the provided context, the minim\n",
      "Question 83: What does SafeBalance Simple banking sol\n",
      "Answer: Based on the context provided, SafeBalan\n",
      "Question 84: What are the advanantages of the Flexibl\n",
      "Answer: Based on the context, the advantages of \n",
      "Question 85: What is the monthly maintenance fee for \n",
      "Answer: The monthly maintenance fee for Flexible\n",
      "Question 86: What does Flexible Enhanced Checking off\n",
      "Answer: Flexible Enhanced Checking offers Balanc\n",
      "Question 87: What are the key features for the Flexib\n",
      "Answer: Based on the context provided, the key f\n",
      "Question 88: What is the monthly maintenance fee for \n",
      "Answer: The monthly maintenance fee for the Flex\n",
      "Question 89: What are the ways to avoid the monthly m\n",
      "Answer: Based on the provided context, there are\n",
      "Question 90: What are the benefits of Parasol Financi\n",
      "Answer: Based on the context provided, all Paras\n",
      "Question 91: Where can you learn to switch to Parasol\n",
      "Answer: Based on the context provided, you can l\n",
      "Question 92: How to get started with the Parasol Loya\n",
      "Answer: To get started with the Parasol Loyalty \n",
      "Question 93: As a sole propeitor, am I subject to the\n",
      "Answer: Yes, as a sole proprietor, you are subje\n",
      "Question 94: Am I subject to the online service agree\n",
      "Answer: Yes, you are subject to the online servi\n",
      "Question 95: If I go in to a Parasol Financial branch\n",
      "Answer: Based on the context provided, the Onlin\n",
      "Question 96: What is the Toll free number for Credit \n",
      "Answer: Based on the provided context, the Toll \n",
      "Question 97: What is the short code number for Mobile\n",
      "Answer: Based on the context provided in the tab\n",
      "Question 98: What is the Toll free number for Credit \n",
      "Answer: The Toll free number for Credit card app\n",
      "Question 99: What is the dollar limit for consumer Ze\n",
      "Answer: Based on the context provided, the dolla\n",
      "Question 100: What is the limit on the number of Zelle\n",
      "Answer: The limit on the number of Zelle transac\n",
      "Question 101: What is the receiving limit or Zelle tra\n",
      "Answer: There are no receiving limits for Zelle \n",
      "Question 102: If my wire transfer is to a family membe\n",
      "Answer: Yes, if your wire transfer is to a famil\n",
      "Question 103: If I have a question about cancelling an\n",
      "Answer: For questions about cancelling an ACH pa\n",
      "Question 104: What kinds of online transfers does are \n",
      "Answer: Based on the context provided, the Paras\n",
      "Question 105: When will I know when my scheduled payme\n",
      "Answer: Based on the context, when you attempt t\n",
      "Question 106: What's the latest I should schedule a bi\n",
      "Answer: Based on the context provided, you shoul\n",
      "Question 107: You failed to process a payment even tho\n",
      "Answer: Based on the context, if Parasol Financi\n",
      "Question 108: What are some examples of roles in the B\n",
      "Answer: Based on the provided context, some exam\n",
      "Question 109: What types of roles are included in the \n",
      "Answer: Based on the provided context, the Techn\n",
      "Question 110: What are some Business Support Services \n",
      "Answer: Based on the context provided, Business \n",
      "Question 111: What are some financial wellness benefit\n",
      "Answer: Based on the context provided, Parasol F\n",
      "Question 112: Does Parasol Financial offer any physica\n",
      "Answer: Based on the provided context, while the\n",
      "Question 113: What kind of emotional wellness support \n",
      "Answer: Based on the provided document, there is\n",
      "Question 114: Does Parasol Financial offer tuition ass\n",
      "Answer: Yes, Parasol Financial does offer tuitio\n",
      "Question 115: What is a responsibility of the Software\n",
      "Answer: Based on the context provided, one respo\n",
      "Question 116: What kind of skills should a software en\n",
      "Answer: Based on the context provided, a Softwar\n",
      "Question 117: What are the responsbilities of a Cyber \n",
      "Answer: Based on the context provided, the respo\n",
      "Question 118: What is taking ownership and demonstrati\n",
      "Answer: Taking ownership is about demonstrating \n",
      "Question 119: How do you resolve a customer's issue?\n",
      "Answer: To resolve a customer's issue, you shoul\n",
      "Question 120: What are the types of questions I should\n",
      "Answer: Based on the context, when taking owners\n",
      "Question 121: What are some phrases to avoid using whe\n",
      "Answer: Based on the provided context, some phra\n",
      "Question 122: What could I say instead of \"I don't kno\n",
      "Answer: Based on the context provided, instead o\n",
      "Question 123: How can I project confidence in resolvin\n",
      "Answer: # How to Project Confidence in Resolving\n",
      "Question 124: What is a good thing to consider when re\n",
      "Answer: Based on the context provided, a good th\n",
      "Question 125: What is a good way to interact with a fr\n",
      "Answer: Based on the context, a good way to inte\n",
      "Question 126: What is a bad way to interact with a fru\n",
      "Answer: Based on the context provided, a bad way\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import chat_request, get_testing_config_name\n",
    "reference_answers_df = pd.DataFrame(reference_answers)\n",
    "\n",
    "for testing_config in config[\"testing_configs\"]:\n",
    "    print(\"-\" * 80)\n",
    "    print(testing_config.get(\"name\") or testing_config.get(\"model_name\"))\n",
    "    responses = reference_answers_df.copy()\n",
    "    responses[\"response\"] = \"\"\n",
    "    llm = create_llm(testing_config)\n",
    "    for index, row in responses.iterrows():\n",
    "        question = row[\"user_input\"]\n",
    "        print(f\"Question {index + 1}:\", question[:40])\n",
    "        if testing_config.get(\"rag\"):\n",
    "            retrieved_context = row[\"retrieved_context\"]\n",
    "        else:\n",
    "            retrieved_context = None\n",
    "        answer = chat_request(llm, testing_config.get(\"template\"), question, retrieved_context)\n",
    "        print(\"Answer: \" + answer[:40])\n",
    "        responses.at[index, \"response\"] = answer\n",
    "    testing_config_name = get_testing_config_name(testing_config)\n",
    "    responses.to_json(f\"{responses_directory}/{testing_config_name}_responses.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9817c4a2b04b2",
   "metadata": {},
   "source": [
    "## Grade responses using InstructLab\n",
    "\n",
    "Now that we have the responses from each of the models, we can grade the responses using InstructLab.  We will save the scores in a `ilab_scores` directory for each model.  The scores will be saved in a `jsonl` file with the format of `user_input`, `reference`, `retrieved_context`, `response`, `score`.  InstructLab will utilize Ragas along with ChatGPT-4o as a Judge Model to score the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27570f629f22ebbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:50:45.229935Z",
     "start_time": "2025-02-05T23:50:45.219387Z"
    }
   },
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "output_directory = get_output_dir()\n",
    "responses_directory = output_directory + \"/responses\"\n",
    "ilab_scores_directory = output_directory + \"/ilab_scores\"\n",
    "os.makedirs(ilab_scores_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7343834679ec5001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:50:54.642503Z",
     "start_time": "2025-02-05T23:50:45.554628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "claude_3_7_sonnet\n",
      "finetuned_eval/responses/claude_3_7_sonnet_responses.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaredia/dev/rhel-ai-poc/eval/instructlab_ragas.py:220: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  critic_lm = ChatOpenAI(model=judge_model_name, api_key=judge_openai_api_key)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cbac139c994ddf91140012761e3bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86a17c07b4b49ceb5af4d79a9943034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1/32:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from instructlab_ragas import ModelConfig, RagasEvaluator, RunConfig, Sample\n",
    "import os\n",
    "\n",
    "for testing_config in config[\"testing_configs\"]:\n",
    "    testing_config_name = get_testing_config_name(testing_config)\n",
    "    print(\"-\" * 80)\n",
    "    print(testing_config_name)\n",
    "\n",
    "    responses_filename = f\"{responses_directory}/{testing_config_name}_responses.jsonl\"\n",
    "    print(responses_filename)\n",
    "    responses = pd.read_json(responses_filename, orient=\"records\", lines=True)\n",
    "    responses_list = responses[[\"user_input\", \"reference\", \"response\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config[\"judge\"][\"api_key\"]\n",
    "    evaluator = RagasEvaluator()\n",
    "    evaluation_result = evaluator.run(dataset=responses_list)\n",
    "\n",
    "    scores = pd.DataFrame(responses_list)\n",
    "    scores[\"score\"] = [score[\"domain_specific_rubrics\"] for score in evaluation_result.scores]\n",
    "    scores_filename = f\"{ilab_scores_directory}/{testing_config_name}_scores\"\n",
    "    scores.to_json(f\"{scores_filename}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74f2910d1b7718",
   "metadata": {},
   "source": [
    "## Grade responses using OpenAI ChatGPT-4o as a Judge Model\n",
    "\n",
    "Alternatively, you can customize and score the responses using OpenAI ChatGPT-4o as a judge model and your own custom template from the `judge` field in the config.yaml.\n",
    "\n",
    "```yaml\n",
    "name: my-eval # this determines the output directory of the evaluation.\n",
    "judge:\n",
    "  endpoint_url: '' # defaults to OpenAI API endpoint\n",
    "  model_name: gpt-4o\n",
    "  api_key: your-openai-key\n",
    "  template: |\n",
    "    You are an evaluation system tasked with assessing the answer quality of a AI generated response in relation to the posed question and reference answer. Assess if the response is correct, accurate, and factual based on the reference answer.\n",
    "    For evaluating factuality of the answer look at the reference answer compare the model answer to it.\n",
    "    Evaluate the answer_quality as:\n",
    "    - Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "    - Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "    - Score 3: The response is somewhat correct, accurate, and/or factual.\n",
    "    - Score 4: The response is mostly correct, accurate, and factual.\n",
    "    - Score 5: The response is completely correct, accurate, and factual.\n",
    "    Here is the question: \\n ------- \\n {question} \\n -------\n",
    "    Here is model answer: \\n ------- \\n {answer} \\n -------\n",
    "    Here is the reference answer(may be very short and lack details or indirect, long and extractive):  \\n ------- \\n {reference_answer} \\n ------- \\n\n",
    "    Assess the quality of model answer with respect to the Reference Answer, but do not penalize the model answer for adding details or give a direct answer to user question.\n",
    "    Approach your evaluation in step-by-step manner.\n",
    "    For evaluating first list out keys facts covered in the reference answer and check how many are covered by the model answer.\n",
    "    If the question or reference answer is about steps then check if the steps and their order in model answer match with reference answer.\n",
    "    Provide your response as JSON object with two keys: 'reasoning' and 'answer_quality'.\n",
    "```\n",
    "\n",
    "From this template, ChatGPT-4o will return a JSON object with the `answer_quality` and `reasoning` fields.  The `answer_quality` field will be a score between 1 and 5, with 5 being the best score.  The `reasoning` field will provide a reason for the score.\n",
    "\n",
    "We will save the scores in a `openai_scores` directory for each model.  The scores will be saved in a `jsonl` file with the format of `user_input`, `reference`, `retrieved_context`, `response`, `score`, and `reasoning`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd38e7861cf4ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:53:20.385085Z",
     "start_time": "2025-02-05T23:53:20.375865Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from eval_utils import get_config, get_output_dir\n",
    "\n",
    "config = get_config()\n",
    "output_directory = get_output_dir()\n",
    "responses_directory = output_directory + \"/responses\"\n",
    "openai_scores_directory = output_directory + \"/openai_scores\"\n",
    "os.makedirs(openai_scores_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e356f321ec521d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:53:20.827569Z",
     "start_time": "2025-02-05T23:53:20.825830Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "scoring_template_str = config[\"judge\"].get(\"template\")\n",
    "assert scoring_template_str\n",
    "SCORING_PROMPT = PromptTemplate.from_template(scoring_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a7a15b14cd0bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:53:21.432796Z",
     "start_time": "2025-02-05T23:53:21.421204Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "judge_client = OpenAI(api_key=config[\"judge\"][\"api_key\"])\n",
    "judge_model_name = config[\"judge\"][\"model_name\"]\n",
    "\n",
    "def openai_score_request(question, answer, reference_answer):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": SCORING_PROMPT.format(\n",
    "                question=question,\n",
    "                answer=answer,\n",
    "                reference_answer=reference_answer\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = judge_client.chat.completions.create(\n",
    "        model=judge_model_name,\n",
    "        messages=messages,\n",
    "        n=1,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    response_content = completion.choices[0].message.content\n",
    "    response_content = re.sub(r'^```json', '', response_content)\n",
    "    response_content = re.sub(r'```$', '', response_content)\n",
    "    try:\n",
    "        result = json.loads(response_content)\n",
    "    except Exception as e:\n",
    "        result = {\"answer_quality\": 0, \"reasoning\": \"Error\"}\n",
    "        print(\"response_content:\", response_content)\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    score = result[\"answer_quality\"]\n",
    "    reasoning = result[\"reasoning\"]\n",
    "    return score, reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6786d88e859ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T00:00:16.695709Z",
     "start_time": "2025-02-05T23:59:37.251149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "claude_3_7_sonnet\n",
      "Question 1: What is the monthly maintenance fee for the Parasol Financial Flexible Savings account?\n",
      "Answer: Based on the context provided, the monthly maintenance fee for the Parasol Finan\n",
      "Score: 5 The reference answer provides one key fact: the monthly maintenance fee for the \n",
      "Question 2: How can the monthly maintenance fee for the Parasol Financial Flexible Savings account be waived?\n",
      "Answer: Based on the context provided, the monthly maintenance fee of $8.00 for the Para\n",
      "Score: 5 The reference answer lists four key ways to waive the monthly maintenance fee fo\n",
      "Question 3: Is the Parasol Financial Flexible Savings Account insured by the Federal Deposit Insurance Corporation (FDIC)\n",
      "Answer: Yes, the Parasol Financial Flexible Savings Account is insured by the Federal De\n",
      "Score: 5 The reference answer states that the Parasol Financial Flexible Savings Account \n",
      "Question 4: How is interest calculated on the Parasol Financial Flexible Savings account?\n",
      "Answer: Based on the context provided, there is no specific information about how intere\n",
      "Score: 2 The reference answer provides specific details on how interest is calculated on \n",
      "Question 5: What is extra interest?\n",
      "Answer: Based on the context provided, extra interest (also referred to as \"interest rat\n",
      "Score: 5 The reference answer provides the following key facts: 1) Extra interest is earn\n",
      "Question 6: Where can I find current interest rate information?\n",
      "Answer: You can find current interest rate information by checking parasolfinancial.com,\n",
      "Score: 5 The reference answer provides three key methods to find current interest rate in\n",
      "Question 7: Does the Parasol Financial Flexible Savings account charge overdraft fees?\n",
      "Answer: Based on the context provided, it is stated that \"There may still be times when \n",
      "Score: 5 The reference answer provides a clear and direct response to the question, stati\n",
      "Question 8: What happens if I don't have enough money in my account to cover a transaction?\n",
      "Answer: If you don't have enough money in your account to cover a transaction, several t\n",
      "Score: 4 The reference answer states that if there is not enough money in the account, th\n",
      "Question 9: Can I be charged a fee by a merchant or third party if my transaction is declined due to insufficient funds?\n",
      "Answer: Yes, you can be charged a fee by a merchant or third party if your transaction i\n",
      "Score: 5 The reference answer states that a merchant or third party could charge a fee, s\n",
      "Question 10: Are there any ATM fees for withdrawls from a Parasol Financial ATM for the Flexible Savings account?\n",
      "Answer: Based on the context provided, there is no explicit information about ATM fees s\n",
      "Score: 3 The reference answer clearly states that there are no ATM fees for withdrawals f\n",
      "Question 11: What are the ATM fees for a withdrawl from a Non-Parasol Financial ATM within the U.S.?\n",
      "Answer: Based on the context provided, the ATM fee for a withdrawal from a Non-Parasol F\n",
      "Score: 5 The reference answer provides two key facts: 1) There is a $2.50 fee for a withd\n",
      "Question 12: What is the fee for a cashiers check for the Flexible Savings account?\n",
      "Answer: Based on the context provided, the fee for a cashier's check for the Flexible Mo\n",
      "Score: 2 The reference answer states that the fee for a cashier's check from the Flexible\n",
      "Question 13: What are the ATM fees for a withdrawal from a Non-Parasol Financial ATM?\n",
      "Answer: For a withdrawal from a Non-Parasol Financial ATM, the fees are:\n",
      "\n",
      "- $2.50 for AT\n",
      "Score: 5 The reference answer provides the following key facts: 1) A $2.50 fee is charged\n",
      "Question 14: What is the Penny Saved savings program?\n",
      "Answer: The Penny Saved savings program is an automatic savings feature offered by Paras\n",
      "Score: 5 The reference answer provides a brief description of the Penny Saved savings pro\n",
      "Question 15: Can I make purchases with my debit card to qualify for the Penny Saved savings program?\n",
      "Answer: Yes, you can make purchases with your debit card to qualify for the Penny Saved \n",
      "Score: 5 The reference answer states that debit card purchases can be rounded up for the \n",
      "Question 16: Where do the savings from the Penny Saved savings program get deposited\n",
      "Answer: Based on the context provided, the savings from the Penny Saved savings program \n",
      "Score: 5 The reference answer states that the savings from the Penny Saved savings progra\n",
      "Question 17: What is the minimum amount when opening an account?\n",
      "Answer: Based on the provided context, I cannot determine the minimum amount required wh\n",
      "Score: 1 The reference answer provides a specific fact: the minimum amount to open an acc\n",
      "Question 18: Does this account type earn any interest?\n",
      "Answer: Yes, this account type does earn interest. The account has a variable interest r\n",
      "Score: 4 The reference answer provides the following key facts: 1) The account earns inte\n",
      "Question 19: Is there an account monthly maintenance fee ?\n",
      "Answer: Yes, there are monthly maintenance fees for different accounts mentioned in the \n",
      "Score: 5 The reference answer states that there is a monthly maintenance fee of $25.00, w\n",
      "Question 20: Is there a policy to help me avoid overdraft fees on my Flexible Premier Checking account?\n",
      "Answer: Yes, there is a policy to help you avoid overdraft fees on your Flexible Premier\n",
      "Score: 4 The reference answer provides a specific policy to help avoid overdraft fees: th\n",
      "Question 21: What are my options to elect for overdraft settings?\n",
      "Answer: Based on the context, you have two options for overdraft settings:\n",
      "\n",
      "1. Option 1:\n",
      "Score: 5 The reference answer provides two key facts: there are two overdraft setting opt\n",
      "Question 22: If I don't pick an overdraft setting, which one applies?\n",
      "Answer: If you don't pick an overdraft setting, Option 1: Standard will be automatically\n",
      "Score: 5 The reference answer provides a single key fact: if no overdraft setting is chos\n",
      "Question 23: When will cash deposits be available?\n",
      "Answer: Based on the context provided, cash deposits will be available on the day the ba\n",
      "Score: 5 The reference answer states that cash, direct deposits, and wire transfers will \n",
      "Question 24: When will check deposits be available?\n",
      "Answer: Based on the context provided, check deposits are usually available the next bus\n",
      "Score: 5 The reference answer states that check deposits are usually available the next b\n",
      "Question 25: When will Mobile Check Deposits be available?\n",
      "Answer: Based on the context provided, Mobile Check Deposits are usually available the n\n",
      "Score: 5 The reference answer provides the following key facts: 1) Mobile Check Deposits \n",
      "Question 26: Is there a specific number that I can call for help?\n",
      "Answer: Yes, there are specific numbers you can call for help, depending on your situati\n",
      "Score: 4 The reference answer provides a single phone number (800.867.5309) that can be c\n",
      "Question 27: Is there a website to review features and benefits of an account?\n",
      "Answer: Yes, according to the context, you can review all the features and benefits of y\n",
      "Score: 5 The reference answer provides a direct response to the question by stating the w\n",
      "Question 28: How do you schedule an appointment with Parasol Financial?\n",
      "Answer: Based on the context provided, you can schedule an appointment to visit a financ\n",
      "Score: 5 The reference answer provides a specific URL (parasolfinancial.com/appointments)\n",
      "Question 29: Are there any other fees for international wire transfers?\n",
      "Answer: Yes, there are other fees for international wire transfers. According to the con\n",
      "Score: 5 The reference answer mentions that other fees may apply for international wire t\n",
      "Question 30: Do foreign taxes apply to international wire transfers?\n",
      "Answer: Based on the context provided, foreign taxes may apply to international wire tra\n",
      "Score: 5 The reference answer states that foreign taxes may apply to international wire t\n",
      "Question 31: Is there anything else to consider before sending an international wire transfer?\n",
      "Answer: Yes, before sending an international wire transfer, you should consider several \n",
      "Score: 5 The reference answer highlights the importance of considering factors that impac\n",
      "Question 32: What is the monthly maintenance fee of the Flexible Money Market Savings Account?\n",
      "Answer: Based on the context provided, the monthly maintenance fee of the Flexible Money\n",
      "Score: 5 The reference answer provides the key fact that the monthly maintenance fee of t\n",
      "Question 33: How can you avoid the monthly maintenance fee for the Flexible Money Market Savings Account?\n",
      "Answer: Based on the context provided, you can avoid the Monthly Maintenance Fee for the\n",
      "Score: 5 The reference answer provides three key ways to avoid the monthly maintenance fe\n",
      "Question 34: Is the Flexible Money Market Savings insured by the Federal Deposit Insurance Corporation (FDIC)?\n",
      "Answer: Yes, the Flexible Money Market Savings account is insured by the Federal Deposit\n",
      "Score: 5 The reference answer states that the Flexible Money Market Savings is insured by\n",
      "Question 35: When are check deposits available on a Rewards Money and Market Savings account?\n",
      "Answer: Based on the context provided, check deposits on a Rewards Money and Market Savi\n",
      "Score: 5 The reference answer states that check deposits on a Rewards Money and Market Sa\n",
      "Question 36: When are cash deposits available on a Rewards Money and Market Savings account?\n",
      "Answer: Based on the context provided, cash deposits are available on the day they are r\n",
      "Score: 5 The reference answer provides a single key fact: 'Cash deposits are available on\n",
      "Question 37: When are mobile check deposits available on a Rewards Money and Market Savings account?\n",
      "Answer: Based on the context provided, mobile check deposits are usually available the n\n",
      "Score: 5 The reference answer states that mobile check deposits are usually available the\n",
      "Question 38: What is the ATM fee for using Parasol Financial ATMs for the Rewards Money and Market Savings account?\n",
      "Answer: Based on the provided context, there is no ATM fee for using Parasol Financial A\n",
      "Score: 5 The reference answer states that there are no ATM fees for Parasol Financial ATM\n",
      "Question 39: What is the ATM fee for using Non-Parasol Financial ATMs for the Rewards Money and Market Savings account?\n",
      "Answer: Based on the provided context, the ATM fees for using Non-Parasol Financial ATMs\n",
      "Score: 5 The reference answer provides two key facts: 1) There is a fee of $2.50 for usin\n",
      "Question 40: What is the fee for a cashier's check from the Rewards Money and Market Savings account?\n",
      "Answer: Based on the context provided, I see conflicting information about the fee for a\n",
      "Score: 3 The reference answer provides a specific fee of $10 for a cashier's check from t\n",
      "Question 41: Where can I find the interest rate currently applied to my Rewards Money Market account?\n",
      "Answer: Based on the context provided, you can find the current interest rate applied to\n",
      "Score: 5 The reference answer provides two methods to find the interest rate: visiting pa\n",
      "Question 42: Is the interest rate on a Rewards Money Market account fixed or variable?\n",
      "Answer: Based on the context provided, the interest rate on a Rewards Money Market accou\n",
      "Score: 5 The reference answer states that the interest rate on a Rewards Money Market acc\n",
      "Question 43: How is the interest rate booster earned on the Rewards Money Market account?\n",
      "Answer: Based on the provided context, the interest rate booster is earned automatically\n",
      "Score: 5 The reference answer provides the following key facts: 1) The interest rate boos\n",
      "Question 44: What is the overdraft item fee for the Rewards Money Market account.\n",
      "Answer: Based on the provided context, there are two different overdraft item fees menti\n",
      "Score: 3 The reference answer provides a single key fact: the overdraft item fee is $35 p\n",
      "Question 45: What is the maximum number of overdraft item fees that can be charged per day on the Rewards Money Market account?\n",
      "Answer: Based on the provided context, for the Rewards Money Market account, the maximum\n",
      "Score: 1 The reference answer states that no more than 4 Overdraft or Returned Item fees \n",
      "Question 46: What is the Overdraft Protection Transfer Fee on the Rewards Money Market account?\n",
      "Answer: Based on the provided context, the Overdraft Protection Transfer Fee is $12.00 p\n",
      "Score: 5 The reference answer provides two key facts: 1) The Overdraft Protection Transfe\n",
      "Question 47: How much do I need to open a Core Checking account?\n",
      "Answer: Based on the context provided, you need a minimum opening deposit of $25 or more\n",
      "Score: 5 The reference answer states that the opening deposit amount for the Flexible Cor\n",
      "Question 48: Is there a monthly maintenance fee for the Flexible Core Checking and Core Checking for Family Banking accounts?\n",
      "Answer: Yes, there is a monthly maintenance fee of $4.95 for both the Flexible Core Chec\n",
      "Score: 5 The reference answer provides the following key facts: 1) There is a monthly mai\n",
      "Question 49: What are the ATM fees for use of Non-Parasol Financial ATMs outside the U.S.?\n",
      "Answer: The ATM fees for use of Non-Parasol Financial ATMs outside the U.S. are $5.00, p\n",
      "Score: 5 The reference answer provides two key facts: 1) The fee for using a Non-Parasol \n",
      "Question 50: Are there bank overdraft fees on this account?\n",
      "Answer: Yes, there are bank overdraft fees on this account. According to the context, th\n",
      "Score: 1 The reference answer clearly states that there are no bank overdraft fees on the\n",
      "Question 51: How soon are cash deposits available?\n",
      "Answer: Based on the context provided, cash deposits are available on the day the bank r\n",
      "Score: 4 The reference answer states that cash deposits to Flexible Core Checking and Cor\n",
      "Question 52: If my account has a negative balance will I be charged?\n",
      "Answer: Based on the context provided, if your account has a negative balance, you won't\n",
      "Score: 5 The reference answer provides a specific condition under which the account holde\n",
      "Question 53: What are the fees for a replacement card?\n",
      "Answer: Based on the context provided, the fees for a replacement card are:\n",
      "\n",
      "- No fee fo\n",
      "Score: 4 The reference answer states that there is no fee for a replacement card for Flex\n",
      "Question 54: What is the fee for an International wire transfer?\n",
      "Answer: Based on the context provided, the fee for an International wire transfer varies\n",
      "Score: 4 The reference answer provides two key facts: 1) The incoming international wire \n",
      "Question 55: Can Core Checking for Family Banking accounts receive incoming wire transfers?\n",
      "Answer: No, Core Checking for Family Banking accounts cannot receive incoming wire trans\n",
      "Score: 5 The reference answer provides a clear and direct response to the question, stati\n",
      "Question 56: Where can I view all the features and benefits of a Parasol Financial Advantage Core Checking account?\n",
      "Answer: Based on the context, you can view all the features and benefits of your new acc\n",
      "Score: 5 The reference answer provides a specific URL, parasolfinancial.com/quickstart, w\n",
      "Question 57: How can I schedule an appointment to visit a Parasol Financial financial center?\n",
      "Answer: Based on the context provided, you can schedule an appointment to visit a Paraso\n",
      "Score: 5 The reference answer provides a specific URL (parasolfinancial.com/appointments)\n",
      "Question 58: What is the phone number to call Parasol Financial about my Core Checking account?\n",
      "Answer: Based on the provided context, the phone number to call Parasol Financial about \n",
      "Score: 5 The reference answer provides the phone number to call Parasol Financial, which \n",
      "Question 59: What are the payment options for Parasol Financial Advantage Core Checking accounts?\n",
      "Answer: Based on the provided context, I cannot give specific information about payment \n",
      "Score: 1 The reference answer provides specific payment options for the Parasol Financial\n",
      "Question 60: Can I write a personal chack on my Parasol Financial Advantage Core Checking account?\n",
      "Answer: Based on the provided context, I cannot determine whether you can write a person\n",
      "Score: 1 The reference answer clearly states that personal checks cannot be written for t\n",
      "Question 61: Does mobile banking require a mobile app?\n",
      "Answer: Yes, mobile banking requires a mobile app. According to the context, \"Mobile Ban\n",
      "Score: 5 The reference answer states that a mobile banking app is necessary for mobile ba\n",
      "Question 62: What are the ATM fees for the Flexible Enhanced checking account when using Parasol Financial ATMs?\n",
      "Answer: For the Parasol Financial Flexible Enhanced Checking account, there is no ATM fe\n",
      "Score: 5 The reference answer states that there are no fees for the Flexible Enhanced che\n",
      "Question 63: What is the opening deposit amount for the Flexible Enhanced checking account?\n",
      "Answer: The opening deposit amount for the Parasol Financial Flexible Enhanced Checking \n",
      "Score: 4 The reference answer provides a single key fact: the opening deposit amount for \n",
      "Question 64: What is one way you avoid fees on a Flexible Enhanced checking account?\n",
      "Answer: One way to avoid fees on a Flexible Enhanced checking account is through direct \n",
      "Score: 3 The reference answer provides one specific way to avoid fees on a Flexible Enhan\n",
      "Question 65: Are there overdraft fees for the Parasol Financial Flexible Enhanced checking account?\n",
      "Answer: No, there are no overdraft fees for the Parasol Financial Flexible Enhanced chec\n",
      "Score: 2 The reference answer states that there may be overdraft fees if a payment is aut\n",
      "Question 66: Will ATM withdrawals be authorized if there isn't enough money in my account?\n",
      "Answer: Based on the provided context, ATM withdrawals will not be authorized if there i\n",
      "Score: 5 The reference answer provides a clear and direct response to the question, stati\n",
      "Question 67: Will a scheduled payment be authorized if there isn't enough money in my account?\n",
      "Answer: Based on the provided context, a scheduled payment may or may not be authorized \n",
      "Score: 5 The reference answer states that scheduled payments may or may not be authorized\n",
      "Question 68: What is the default setting for Overdraft fees on Flexible Enhanced checking accounts?\n",
      "Answer: Based on the context provided, the default setting for Overdraft fees is Option \n",
      "Score: 5 The reference answer states that Option 1 is automatically applied to the accoun\n",
      "Question 69: What is overdraft setting option 1?\n",
      "Answer: Option 1 is the \"Standard\" overdraft setting. This setting is automatically appl\n",
      "Score: 5 The reference answer outlines three key facts about overdraft setting option 1: \n",
      "Question 70: What is the overdraft fee per item?\n",
      "Answer: Based on the context provided, the overdraft fee per item is $10.00. This is sta\n",
      "Score: 5 The reference answer provides the key fact that the overdraft fee per item is $1\n",
      "Question 71: Is there a overdraft item fee when option 2 is selected?\n",
      "Answer: No, there is no overdraft item fee when Option 2 (Decline All) is selected. The \n",
      "Score: 5 The reference answer provides a clear and direct response to the question, stati\n",
      "Question 72: What is overdraft setting option 2?\n",
      "Answer: Option 2 is \"Decline All\", which is a setting customers can choose if they want \n",
      "Score: 5 The reference answer provides the following key facts: 1) Overdraft setting opti\n",
      "Question 73: Is there a fee charged if a transaction is declined?\n",
      "Answer: According to the context, if the bank declines or returns a transaction due to i\n",
      "Score: 4 The reference answer states that there is no fee charged by the bank if a transa\n",
      "Question 74: If I have selected the Decline All overdraft policy, will money be pulled from my other accounts to cover a transaction?\n",
      "Answer: Based on the context, if you have selected the Decline All overdraft policy, mon\n",
      "Score: 5 The reference answer provides a key fact: if Balance Link is set up, funds will \n",
      "Question 75: What are the order of trasactions categories that can be posted to accounts?\n",
      "Answer: Based on the context provided, the order of transaction categories that can be p\n",
      "Score: 5 The reference answer lists the transaction categories in the following order: 1.\n",
      "Question 76: Does the order transactions are posted impact the number of overdraft fees?\n",
      "Answer: Yes, the order in which transactions are posted does impact the number of overdr\n",
      "Score: 5 The reference answer states that the order of transactions may impact the number\n",
      "Question 77: Do transactions that are still processing lower the available balance?\n",
      "Answer: Yes, transactions that are still processing may lower your available balance. Th\n",
      "Score: 5 The reference answer states that transactions that are still processing may lowe\n",
      "Question 78: Is the Flexible Core Checking account available for children under 6 years old?\n",
      "Answer: Based on the context provided, it's not explicitly stated that the Flexible Core\n",
      "Score: 4 The reference answer clearly states that the Flexible Core Checking account is a\n",
      "Question 79: What is the minimum balance required to avoid the monthly maintenance fee for the Flexible Core Checking account for my child?\n",
      "Answer: The minimum daily balance required to avoid the monthly maintenance fee for the \n",
      "Score: 5 The reference answer states that the minimum balance required to avoid the month\n",
      "Question 80: What is the monthly maintenance fee for the Flexible Core Checking account for my family?\n",
      "Answer: Based on the context provided, the monthly maintenance fee for the Flexible Core\n",
      "Score: 5 The reference answer provides two key facts: 1) The monthly maintenance fee for \n",
      "Question 81: Who is the target audience for the SafeBalance Simple Banking account?\n",
      "Answer: Based on the provided context, I don't see any specific information about a \"Saf\n",
      "Score: 1 The reference answer clearly states that the target audience for the SafeBalance\n",
      "Question 82: What is the minimum balance for the SafeBalance Simple Banking account?\n",
      "Answer: Based on the provided context, the minimum daily balance required to waive the m\n",
      "Score: 5 The reference answer provides the following key facts: 1) The minimum balance to\n",
      "Question 83: What does SafeBalance Simple banking solve for you ?\n",
      "Answer: Based on the context provided, SafeBalance Simple banking helps prevent you from\n",
      "Score: 4 The reference answer highlights three key facts about SafeBalance Simple banking\n",
      "Question 84: What are the advanantages of the Flexible Enhanced Checking account?\n",
      "Answer: Based on the context, the advantages of the Flexible Enhanced Checking account i\n",
      "Score: 5 The reference answer lists three key advantages of the Flexible Enhanced Checkin\n",
      "Question 85: What is the monthly maintenance fee for Flexible Enhanced Checking?\n",
      "Answer: The monthly maintenance fee for Flexible Enhanced Checking is $12.00 each month,\n",
      "Score: 5 The reference answer provides two key facts: 1) The monthly maintenance fee for \n",
      "Question 86: What does Flexible Enhanced Checking offer for overdraft protection ?\n",
      "Answer: Flexible Enhanced Checking offers Balance Link for overdraft protection. Balance\n",
      "Score: 5 The reference answer states that Flexible Enhanced Checking offers Balance Link \n",
      "Question 87: What are the key features for the Flexible Premier Checking account?\n",
      "Answer: Based on the context provided, the key features for the Flexible Premier Checkin\n",
      "Score: 5 The reference answer lists three key features of the Flexible Premier Checking a\n",
      "Question 88: What is the monthly maintenance fee for the Flexible Premier Checking account?\n",
      "Answer: The monthly maintenance fee for the Flexible Premier Checking account is $25.00 \n",
      "Score: 4 The reference answer provides two possible monthly maintenance fees for the Flex\n",
      "Question 89: What are the ways to avoid the monthly maintenance fee for the Flexible Premier Checking account?\n",
      "Answer: Based on the provided context, there are two ways to avoid the monthly maintenan\n",
      "Score: 5 The reference answer provides two key facts for avoiding the monthly maintenance\n",
      "Question 90: What are the benefits of Parasol Financial Flexible Checking despite the account type?\n",
      "Answer: Based on the context provided, all Parasol Financial Flexible Checking accounts,\n",
      "Score: 5 The reference answer lists three key benefits of Parasol Financial Flexible Chec\n",
      "Question 91: Where can you learn to switch to Parasol Financial ?\n",
      "Answer: Based on the context provided, you can learn how to switch your account to Paras\n",
      "Score: 5 The reference answer provides a specific URL where one can learn to switch to Pa\n",
      "Question 92: How to get started with the Parasol Loyalty program?\n",
      "Answer: To get started with the Parasol Loyalty program, you need to:\n",
      "\n",
      "1. Have an active\n",
      "Score: 4 The reference answer provides minimal information, simply suggesting to contact \n",
      "Question 93: As a sole propeitor, am I subject to the terms applicable to a small business?\n",
      "Answer: Yes, as a sole proprietor, you are subject to the terms applicable to a small bu\n",
      "Score: 5 The reference answer provides a clear statement that the term 'small business' i\n",
      "Question 94: Am I subject to the online service agreement as a user of the mobile phone app?\n",
      "Answer: Yes, you are subject to the online service agreement as a user of the mobile pho\n",
      "Score: 5 The reference answer states that the Parasol Financial Online Banking Service Ag\n",
      "Question 95: If I go in to a Parasol Financial branch and work with a customer service agent, am I subject to the Online Banking Service Agreement?\n",
      "Answer: Based on the context provided, the Online Banking Service Agreement specifically\n",
      "Score: 5 The reference answer provides the key fact that the Online Banking Service Agree\n",
      "Question 96: What is the Toll free number for Credit Card enquiries?\n",
      "Answer: Based on the provided context, the Toll Free Number for Credit Card enquiries is\n",
      "Score: 5 The reference answer provides the Toll Free Number for Credit Card enquiries as \n",
      "Question 97: What is the short code number for Mobile Wallet enquiries?\n",
      "Answer: Based on the context provided in the table, the short code number for Mobile Wal\n",
      "Score: 5 The reference answer provides the short code number for Mobile Wallet enquiries \n",
      "Question 98: What is the Toll free number for Credit card application?\n",
      "Answer: The Toll free number for Credit card application is 800.867.5298, as shown in th\n",
      "Score: 5 The reference answer provides the Toll free number for Credit card applications \n",
      "Question 99: What is the dollar limit for consumer Zelle transactions in a 24 hour period?\n",
      "Answer: Based on the context provided, the dollar limit for consumer Zelle transactions \n",
      "Score: 5 The reference answer provides two key facts: the dollar limit for consumer Zelle\n",
      "Question 100: What is the limit on the number of Zelle transactions in a 7 day period for consumer transactions?\n",
      "Answer: The limit on the number of Zelle transactions in a 7-day period for consumer tra\n",
      "Score: 5 The reference answer provides a key fact: the limit is 30 transactions every 7 d\n",
      "Question 101: What is the receiving limit or Zelle transfers?\n",
      "Answer: There are no receiving limits for Zelle transfers, as stated in the context: \"Th\n",
      "Score: 5 The reference answer states that there is no receiving limit for Zelle transfers\n",
      "Question 102: If my wire transfer is to a family member for personal reasons, am I subject to federal law?\n",
      "Answer: Yes, if your wire transfer is to a family member for personal reasons and it's s\n",
      "Score: 5 The reference answer states that if a wire transfer is sent outside of the Unite\n",
      "Question 103: If I have a question about cancelling an ACH payment, who can I talk to?\n",
      "Answer: For questions about cancelling an ACH payment, you can call Parasol Financial at\n",
      "Score: 4 The reference answer provides the following key facts: 1) For questions about ca\n",
      "Question 104: What kinds of online transfers does are covered by the Parasol Financial Online Banking Service Agreement?\n",
      "Answer: Based on the context provided, the Parasol Financial Online Banking Service Agre\n",
      "Score: 4 The reference answer mentions two key types of online transfers covered by the P\n",
      "Question 105: When will I know when my scheduled payment will be delivered?\n",
      "Answer: Based on the context, when you attempt to schedule a payment, Parasol Financial \n",
      "Score: 5 The reference answer provides a key fact: when you attempt to schedule a payment\n",
      "Question 106: What's the latest I should schedule a bill payment?\n",
      "Answer: Based on the context provided, you should schedule bill payments at least five (\n",
      "Score: 5 The reference answer provides the following key facts: 1) Schedule payments at l\n",
      "Question 107: You failed to process a payment even though I followed the rules. I was charged a late payment fee. What happens now?\n",
      "Answer: Based on the context, if Parasol Financial fails to process a payment according \n",
      "Score: 5 The reference answer contains one key fact: if the payment was not processed acc\n",
      "Question 108: What are some examples of roles in the Banking, Markets & Finance category at Parasol Financial?\n",
      "Answer: Based on the provided context, some examples of roles in the Banking, Markets & \n",
      "Score: 5 The reference answer lists the following roles in the Banking, Markets & Finance\n",
      "Question 109: What types of roles are included in the Technology & Operations category?\n",
      "Answer: Based on the provided context, the Technology & Operations category includes a w\n",
      "Score: 4 The reference answer lists the following roles in the Technology & Operations ca\n",
      "Question 110: What are some Business Support Services roles at a bank?\n",
      "Answer: Based on the context provided, Business Support Services roles at a bank include\n",
      "Score: 4 The reference answer lists the following Business Support Services roles at a ba\n",
      "Question 111: What are some financial wellness benefits offered by Parasol Financial?\n",
      "Answer: Based on the context provided, Parasol Financial offers the following financial \n",
      "Score: 5 The reference answer lists the following financial wellness benefits offered by \n",
      "Question 112: Does Parasol Financial offer any physical wellness benefits to its employees?\n",
      "Answer: Based on the provided context, while the document mentions a \"Physical Wellness\"\n",
      "Score: 2 The reference answer lists several specific physical wellness benefits offered b\n",
      "Question 113: What kind of emotional wellness support does Parasol Financial provide?\n",
      "Answer: Based on the provided document, there is no specific information about emotional\n",
      "Score: 2 The reference answer lists specific emotional wellness supports provided by Para\n",
      "Question 114: Does Parasol Financial offer tuition assistance?\n",
      "Answer: Yes, Parasol Financial does offer tuition assistance. This is mentioned in the \"\n",
      "Score: 5 The reference answer states that Parasol Financial offers tuition assistance as \n",
      "Question 115: What is a responsibility of the Software engineer?\n",
      "Answer: Based on the context provided, one responsibility of a Software Engineer is to d\n",
      "Score: 5 The reference answer states that Software Engineers are responsible for designin\n",
      "Question 116: What kind of skills should a software engineer have?\n",
      "Answer: Based on the context provided, a Software Engineer should have the following ski\n",
      "Score: 5 The reference answer lists the following key skills for a software engineer: ski\n",
      "Question 117: What are the responsbilities of a Cyber Security Analyst?\n",
      "Answer: Based on the context provided, the responsibilities of a Cyber Security Analyst \n",
      "Score: 5 The reference answer lists the responsibilities of a Cyber Security Analyst as: \n",
      "Question 118: What is taking ownership and demonstrating a willingness to help?\n",
      "Answer: Taking ownership is about demonstrating a willingness to help customers. Accordi\n",
      "Score: 4 The reference answer outlines several key facts about taking ownership and demon\n",
      "Question 119: How do you resolve a customer's issue?\n",
      "Answer: To resolve a customer's issue, you should:\n",
      "\n",
      "1. Address their concerns on the fir\n",
      "Score: 4 The reference answer focuses on gathering more context by asking specific questi\n",
      "Question 120: What are the types of questions I should ask a customer to take ownership of their problem?\n",
      "Answer: Based on the context, when taking ownership of a customer's problem, you should \n",
      "Score: 5 The reference answer outlines three types of questions to ask when taking owners\n",
      "Question 121: What are some phrases to avoid using when speaking to a customer?\n",
      "Answer: Based on the provided context, some phrases to avoid when speaking to a customer\n",
      "Score: 3 The reference answer suggests avoiding phrases that are dismissive or unhelpful,\n",
      "Question 122: What could I say instead of \"I don't know?\"\n",
      "Answer: Based on the context provided, instead of saying \"I don't know,\" you could say:\n",
      "\n",
      "Score: 5 The reference answer provides an alternative phrase to 'I don't know,' which is \n",
      "Question 123: How can I project confidence in resolving a customer's issue?\n",
      "Answer: # How to Project Confidence in Resolving a Customer's Issue\n",
      "\n",
      "To project confiden\n",
      "Score: 4 The reference answer provides a single key fact: using strong words is an effect\n",
      "Question 124: What is a good thing to consider when relating to the customer?\n",
      "Answer: Based on the context provided, a good thing to consider when relating to the cus\n",
      "Score: 4 The reference answer suggests using 'welcoming language' when relating to the cu\n",
      "Question 125: What is a good way to interact with a frustrated customer?\n",
      "Answer: Based on the context, a good way to interact with a frustrated customer is to:\n",
      "\n",
      "\n",
      "Score: 5 The reference answer suggests using empathetic language to interact with a frust\n",
      "Question 126: What is a bad way to interact with a frustrated customer?\n",
      "Answer: Based on the context provided, a bad way to interact with a frustrated customer \n",
      "Score: 4 The reference answer highlights the use of unempathetic language as a bad way to\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import replace_special_char\n",
    "\n",
    "for testing_config in config[\"testing_configs\"]:\n",
    "    testing_config_name = get_testing_config_name(testing_config)\n",
    "    print(\"-\" * 80)\n",
    "    print(testing_config_name)\n",
    "\n",
    "    responses_filename = f\"{responses_directory}/{testing_config_name}_responses.jsonl\"\n",
    "    scores = pd.read_json(responses_filename, orient=\"records\", lines=True)\n",
    "    scores[\"score\"] = None\n",
    "    scores[\"reasoning\"] = None\n",
    "\n",
    "    for index, row in scores.iterrows():\n",
    "        user_input = row[\"user_input\"]\n",
    "        response = row[\"response\"]\n",
    "        reference_answer = row[\"reference\"]\n",
    "        print(f\"Question {index + 1}:\", user_input)\n",
    "        if response:\n",
    "            score, reasoning = openai_score_request(user_input, response, reference_answer)\n",
    "            scores.at[index, \"score\"] = score\n",
    "            scores.at[index, \"reasoning\"] = reasoning\n",
    "            print(\"Answer:\", response[:80])\n",
    "            print(\"Score:\", score, reasoning[:80])\n",
    "\n",
    "    judge_name = replace_special_char(judge_model_name)\n",
    "    scores_filename = f\"{openai_scores_directory}/{testing_config_name}_scores\"\n",
    "    scores.to_json(f\"{scores_filename}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026ec6e6c8ba3e5",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Now that we have the scores for each of the models, we can save the results in the `evaluation.json` file. The results will include the `reference_answers`, `ilab_evaluation`, and `openai_evaluation` fields.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"reference_answers\": [\n",
    "        {\"user_input\": \"What is ...\", \"reference\": \"It is...\", \"retrieved_context\": \"There is ...\"},\n",
    "        {\"user_input\": \"What is ...\",\"reference\": \"It is...\",\"retrieved_context\": \"There is ...\"}\n",
    "    ],\n",
    "    \"ilab_evaluation\": {\n",
    "        \"status\": \"complete\",\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"name\": \"lab-tuned-granite\",\n",
    "                \"scores\": [\n",
    "                    {\"user_input\": \"What is ...\", ..., \"score\": 4},\n",
    "                    {\"user_input\": \"What is ...\", ..., \"score\": 4},\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"openai_evaluation\": {\n",
    "        \"status\": \"complete\",\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"name\": \"other-model-rag\",\n",
    "                \"scores\": [\n",
    "                    {\"user_input\": \"What is ...\", ..., \"score\": 4,\"reasoning\": \"The answer...\"}\n",
    "                    {\"user_input\": \"What is ...\", ..., \"score\": 4,\"reasoning\": \"The answer...\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3934047999521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T00:21:50.733182Z",
     "start_time": "2025-02-06T00:21:50.708079Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = get_config()\n",
    "output_directory = get_output_dir()\n",
    "responses_directory = output_directory + \"/responses\"\n",
    "ilab_scores_directory = output_directory + \"/ilab_scores\"\n",
    "openai_scores_directory = output_directory + \"/openai_scores\"\n",
    "os.makedirs(openai_scores_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_eval_results(directory):\n",
    "    results = []\n",
    "    for testing_config in config[\"testing_configs\"]:\n",
    "        testing_config_name = get_testing_config_name(testing_config)\n",
    "        scores = pd.read_json(f\"{directory}/{testing_config_name}_scores.jsonl\", orient=\"records\", lines=True)\n",
    "        results.append({\n",
    "            \"name\": testing_config.get(\"name\") or testing_config.get(\"model_name\"),\n",
    "            \"scores\": scores.to_dict(orient=\"records\")\n",
    "        })\n",
    "    return {\n",
    "        \"status\": \"complete\",\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "evaluation = {}\n",
    "evaluation[\"reference_answers\"] = read_jsonl(f\"{output_directory}/reference_answers.jsonl\")\n",
    "evaluation[\"ilab_evaluation\"] = read_eval_results(ilab_scores_directory)\n",
    "evaluation[\"openai_evaluation\"] = read_eval_results(openai_scores_directory)\n",
    "json.dump(evaluation, open(f\"{output_directory}/evaluation.json\", 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c395a7e84df039f",
   "metadata": {},
   "source": [
    "## Create resulting score report Excel / Markdown / HTML\n",
    "\n",
    "Now that the evaluation is complete, we can summarize the results in an Excel, Markdown, and HTML file for both the InstructLab evaluation and the OpenAI evaluation.  Feel free to use either.  You can find the files in the `results` directory and inspect the results.  The summary scores are between 1 and 5, with 5 being the best score.  The first table is a summary for each model and each model detail, including all the data follows.  If you're worried about the results, this should help diagnose any issues like subpar context retrieval.\n",
    "\n",
    "#### Summary\n",
    "| question index   |   lab-tuned-granite |   lab-tuned-granite-rag |   granite-3.0-8b-instruct-rag | gpt-4-rag |\n",
    "|:-----------------|--------------------:|------------------------:|------------------------------:|----------:|\n",
    "| Q1               |                   4 |                       5 |                             5 |         4 |\n",
    "| Q2               |                   1 |                       5 |                             5 |         5 |\n",
    "| ...              |                 ... |                     ... |                           ... |       ... |\n",
    "| QX               |                   4 |                       5 |                             5 |         5 |\n",
    "| Sum              |                   9 |                      15 |                            15 |        14 |\n",
    "| Average          |                   3 |                       5 |                             5 |   4.66667 |\n",
    "\n",
    "\n",
    "#### lab-tuned-granite\n",
    "| user_input | reference | retrieved_context |  response |   score |     reasoning |\n",
    "|:-----------|----------:|------------------:|----------:|--------:|--------------:|\n",
    "| What is ...| It is...  | There is ...      | It is...  |  4      | The answer... |\n",
    "\n",
    "#### lab-tuned-granite-rag\n",
    "| user_input | reference | retrieved_context |  response |   score |     reasoning |\n",
    "|:-----------|----------:|------------------:|----------:|--------:|--------------:|\n",
    "| What is ...| It is...  | There is ...      | It is...  |  4      | The answer... |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f15ce5ad8037cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T00:28:53.503718Z",
     "start_time": "2025-02-06T00:28:53.496573Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_directory = get_output_dir()\n",
    "eval = json.load(open(f\"{output_directory}/evaluation.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6cee5ca896457a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import summarize_results, write_excel, write_markdown, write_html\n",
    "\n",
    "ilab_summary_output_df = summarize_results(eval.get(\"ilab_evaluation\").get(\"results\"))\n",
    "openai_summary_output_df = summarize_results(eval.get(\"openai_evaluation\").get(\"results\"))\n",
    "\n",
    "write_excel(\n",
    "    ilab_summary_output_df,\n",
    "    eval.get(\"ilab_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/ilab_scores.xlsx\"\n",
    ")\n",
    "\n",
    "write_excel(\n",
    "    openai_summary_output_df,\n",
    "    eval.get(\"openai_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/openai_scores.xlsx\"\n",
    ")\n",
    "\n",
    "write_markdown(\n",
    "    ilab_summary_output_df,\n",
    "    eval.get(\"ilab_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/ilab_scores.md\"\n",
    ")\n",
    "\n",
    "write_markdown(\n",
    "    openai_summary_output_df,\n",
    "    eval.get(\"openai_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/openai_scores.md\"\n",
    ")\n",
    "\n",
    "write_html(\n",
    "    ilab_summary_output_df,\n",
    "    eval.get(\"ilab_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/ilab_scores.html\"\n",
    ")\n",
    "\n",
    "write_html(\n",
    "    openai_summary_output_df,\n",
    "    eval.get(\"openai_evaluation\").get(\"results\"),\n",
    "    f\"{output_directory}/openai_scores.html\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a732e62-9689-4971-9612-1b6e683ba212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
